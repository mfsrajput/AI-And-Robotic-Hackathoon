"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[571],{3430:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>c,frontMatter:()=>o,metadata:()=>a,toc:()=>d});const a=JSON.parse('{"id":"nvidia-isaac/isaac-sim-synthetic-data","title":"Isaac Sim & Synthetic Data Generation","description":"Learning Objectives","source":"@site/docs/03-nvidia-isaac/01-isaac-sim-synthetic-data.md","sourceDirName":"03-nvidia-isaac","slug":"/nvidia-isaac/isaac-sim-synthetic-data","permalink":"/AI-And-Robotic-Hackathoon/nvidia-isaac/isaac-sim-synthetic-data","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/03-nvidia-isaac/01-isaac-sim-synthetic-data.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"Isaac Sim & Synthetic Data Generation"},"sidebar":"moduleSidebar","previous":{"title":"Creating Complete Digital Twins","permalink":"/AI-And-Robotic-Hackathoon/digital-twin/creating-complete-digital-twins"},"next":{"title":"Isaac ROS + Hardware-Accelerated VSLAM","permalink":"/AI-And-Robotic-Hackathoon/nvidia-isaac/isaac-ros-vslam-perception"}}');var t=i(4848),r=i(8453);const o={sidebar_position:1,title:"Isaac Sim & Synthetic Data Generation"},s="Isaac Sim & Synthetic Data Generation",l={},d=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction",id:"introduction",level:2},{value:"Theory: Synthetic Data Generation Fundamentals",id:"theory-synthetic-data-generation-fundamentals",level:2},{value:"Universal Scene Description (USD)",id:"universal-scene-description-usd",level:3},{value:"Domain Randomization",id:"domain-randomization",level:3},{value:"Physically-Based Rendering",id:"physically-based-rendering",level:3},{value:"Practice: Creating Isaac Sim Environments",id:"practice-creating-isaac-sim-environments",level:2},{value:"USD Scene Creation",id:"usd-scene-creation",level:3},{value:"Creating a Domain Randomization Configuration",id:"creating-a-domain-randomization-configuration",level:3},{value:"Isaac Sim Python Script for Data Generation",id:"isaac-sim-python-script-for-data-generation",level:3},{value:"Active Learning Exercise",id:"active-learning-exercise",level:2},{value:"Worked Example: Black-box to Glass-box - Isaac Sim USD Scene with Advanced Materials",id:"worked-example-black-box-to-glass-box---isaac-sim-usd-scene-with-advanced-materials",level:2},{value:"Black-box View",id:"black-box-view",level:3},{value:"Glass-box Implementation",id:"glass-box-implementation",level:3},{value:"Understanding the Implementation",id:"understanding-the-implementation",level:3},{value:"Tiered Assessments",id:"tiered-assessments",level:2},{value:"Tier 1: Basic Understanding",id:"tier-1-basic-understanding",level:3},{value:"Tier 2: Application",id:"tier-2-application",level:3},{value:"Tier 3: Analysis and Synthesis",id:"tier-3-analysis-and-synthesis",level:3},{value:"Mermaid Diagram",id:"mermaid-diagram",level:2},{value:"Summary",id:"summary",level:2},{value:"References",id:"references",level:2}];function m(n){const e={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"isaac-sim--synthetic-data-generation",children:"Isaac Sim & Synthetic Data Generation"})}),"\n",(0,t.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(e.p,{children:"By the end of this chapter, students will be able to:"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Design and implement synthetic data generation pipelines using Isaac Sim"}),"\n",(0,t.jsx)(e.li,{children:"Create physically accurate USD scenes for humanoid robot simulation"}),"\n",(0,t.jsx)(e.li,{children:"Configure domain randomization techniques to improve model generalization"}),"\n",(0,t.jsx)(e.li,{children:"Generate diverse sensor data including RGB, depth, LiDAR, and IMU data"}),"\n",(0,t.jsx)(e.li,{children:"Validate synthetic data quality against real-world sensor characteristics"}),"\n",(0,t.jsx)(e.li,{children:"Implement automated data annotation and labeling systems"}),"\n",(0,t.jsx)(e.li,{children:"Optimize synthetic data generation for deep learning model training"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"introduction",children:"Introduction"}),"\n",(0,t.jsx)(e.p,{children:"NVIDIA Isaac Sim represents a paradigm shift in robotics simulation, providing a physically accurate, photo-realistic simulation environment built on the Universal Scene Description (USD) framework and leveraging NVIDIA's RTX rendering technology. For humanoid robotics, Isaac Sim enables the generation of massive amounts of high-quality synthetic data that can be used to train perception, control, and navigation systems without the need for expensive and time-consuming real-world data collection."}),"\n",(0,t.jsx)(e.p,{children:"Synthetic data generation addresses one of the most significant challenges in robotics: the data bottleneck. Real-world data collection for humanoid robots is expensive, time-consuming, and often dangerous. Isaac Sim solves this by providing a safe, controllable, and highly customizable virtual environment where robots can experience thousands of hours of training data in a fraction of the time and cost."}),"\n",(0,t.jsx)(e.p,{children:"The key advantage of Isaac Sim lies in its ability to generate photorealistic synthetic data with perfect ground truth annotations. This includes semantic segmentation masks, depth maps, 3D bounding boxes, and pose information that would be extremely difficult and expensive to obtain from real-world data."}),"\n",(0,t.jsx)(e.h2,{id:"theory-synthetic-data-generation-fundamentals",children:"Theory: Synthetic Data Generation Fundamentals"}),"\n",(0,t.jsx)(e.h3,{id:"universal-scene-description-usd",children:"Universal Scene Description (USD)"}),"\n",(0,t.jsx)(e.p,{children:"USD is Pixar's scene description format that enables complex 3D scenes to be described, assembled, simulated, and rendered. In Isaac Sim, USD serves as the foundation for:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Scene Assembly"}),": Building complex environments from modular components"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Animation"}),": Defining kinematic and dynamic behaviors"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Rendering"}),": Producing photorealistic images with physically-based rendering"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Simulation"}),": Connecting to NVIDIA PhysX for accurate physics simulation"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Data Generation"}),": Enabling automatic annotation of synthetic data"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"domain-randomization",children:"Domain Randomization"}),"\n",(0,t.jsx)(e.p,{children:"Domain randomization is a technique that introduces controlled variations in the synthetic environment to improve the transfer of models trained on synthetic data to the real world. This includes:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Appearance Randomization"}),": Varying textures, materials, lighting conditions"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Geometry Randomization"}),": Modifying object shapes, sizes, and positions"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Dynamics Randomization"}),": Changing physical properties like friction and mass"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Sensor Randomization"}),": Simulating sensor noise, calibration variations"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"physically-based-rendering",children:"Physically-Based Rendering"}),"\n",(0,t.jsx)(e.p,{children:"Isaac Sim uses physically-based rendering (PBR) to generate photorealistic images that closely match real-world lighting conditions. PBR ensures that:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Materials respond realistically to different lighting conditions"}),"\n",(0,t.jsx)(e.li,{children:"Shadows, reflections, and refractions are physically accurate"}),"\n",(0,t.jsx)(e.li,{children:"Surface properties like roughness and metallic properties are correctly modeled"}),"\n",(0,t.jsx)(e.li,{children:"Global illumination effects are properly simulated"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"practice-creating-isaac-sim-environments",children:"Practice: Creating Isaac Sim Environments"}),"\n",(0,t.jsx)(e.h3,{id:"usd-scene-creation",children:"USD Scene Creation"}),"\n",(0,t.jsx)(e.p,{children:"Let's create a USD scene for humanoid robot training. First, we'll create a basic scene structure:"}),"\n",(0,t.jsxs)(e.p,{children:["Create ",(0,t.jsx)(e.code,{children:"~/isaac_sim_projects/humanoid_training/scene.usd"}),":"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-usda",children:'#usda 1.0\n\ndef Xform "World"\n{\n    def Xform "Environment"\n    {\n        # Ground plane\n        def PhysicsMaterial "ground_material"\n        {\n            float dynamicFriction = 0.5\n            float staticFriction = 0.5\n            float restitution = 0.1\n        }\n\n        def Plane "ground_plane"\n        {\n            double3 extent = (100, 100)\n            PhysicsRigidBodyAPI "physics:rigidBody"\n            {\n                bool physics:kinematicEnabled = 1\n            }\n            PhysicsMaterialBindingAPI "physics:material:binding"\n            {\n                rel physics:material:binding = </World/Environment/ground_material>\n            }\n        }\n\n        # Walls\n        def Cube "wall_front"\n        {\n            double3 size = (100, 0.2, 2)\n            double3 xformOp:translate = (0, -10, 1)\n            PhysicsRigidBodyAPI "physics:rigidBody"\n            {\n                bool physics:kinematicEnabled = 1\n            }\n        }\n\n        def Cube "wall_back"\n        {\n            double3 size = (100, 0.2, 2)\n            double3 xformOp:translate = (0, 10, 1)\n            PhysicsRigidBodyAPI "physics:rigidBody"\n            {\n                bool physics:kinematicEnabled = 1\n            }\n        }\n\n        def Cube "wall_left"\n        {\n            double3 size = (0.2, 20, 2)\n            double3 xformOp:translate = (-10, 0, 1)\n            PhysicsRigidBodyAPI "physics:rigidBody"\n            {\n                bool physics:kinematicEnabled = 1\n            }\n        }\n\n        def Cube "wall_right"\n        {\n            double3 size = (0.2, 20, 2)\n            double3 xformOp:translate = (10, 0, 1)\n            PhysicsRigidBodyAPI "physics:rigidBody"\n            {\n                bool physics:kinematicEnabled = 1\n            }\n        }\n    }\n\n    # Humanoid Robot\n    def Xform "HumanoidRobot"\n    {\n        double3 xformOp:translate = (0, 0, 1.0)\n        add xformOp:orient = (0, 0, 0, 1)\n\n        # Robot body\n        def Capsule "torso"\n        {\n            double radius = 0.15\n            double height = 0.6\n            double3 xformOp:translate = (0, 0, 0.6)\n            add xformOp:orient = (0.707, 0, 0.707, 0)\n        }\n\n        # Head\n        def Sphere "head"\n        {\n            double radius = 0.12\n            double3 xformOp:translate = (0, 0, 1.0)\n        }\n\n        # Arms\n        def Capsule "left_upper_arm"\n        {\n            double radius = 0.05\n            double height = 0.4\n            double3 xformOp:translate = (0.25, 0.15, 0.6)\n            add xformOp:orient = (0.707, 0, 0.707, 0)\n        }\n\n        def Capsule "left_lower_arm"\n        {\n            double radius = 0.04\n            double height = 0.35\n            double3 xformOp:translate = (0.25, 0.15, 0.25)\n            add xformOp:orient = (0.707, 0, 0.707, 0)\n        }\n\n        def Capsule "right_upper_arm"\n        {\n            double radius = 0.05\n            double height = 0.4\n            double3 xformOp:translate = (0.25, -0.15, 0.6)\n            add xformOp:orient = (0.707, 0, 0.707, 0)\n        }\n\n        def Capsule "right_lower_arm"\n        {\n            double radius = 0.04\n            double height = 0.35\n            double3 xformOp:translate = (0.25, -0.15, 0.25)\n            add xformOp:orient = (0.707, 0, 0.707, 0)\n        }\n\n        # Legs\n        def Capsule "left_upper_leg"\n        {\n            double radius = 0.08\n            double height = 0.5\n            double3 xformOp:translate = (-0.1, 0.1, -0.1)\n            add xformOp:orient = (0.707, 0, 0.707, 0)\n        }\n\n        def Capsule "left_lower_leg"\n        {\n            double radius = 0.07\n            double height = 0.45\n            double3 xformOp:translate = (-0.1, 0.1, -0.6)\n            add xformOp:orient = (0.707, 0, 0.707, 0)\n        }\n\n        def Capsule "right_upper_leg"\n        {\n            double radius = 0.08\n            double height = 0.5\n            double3 xformOp:translate = (-0.1, -0.1, -0.1)\n            add xformOp:orient = (0.707, 0, 0.707, 0)\n        }\n\n        def Capsule "right_lower_leg"\n        {\n            double radius = 0.07\n            double height = 0.45\n            double3 xformOp:translate = (-0.1, -0.1, -0.6)\n            add xformOp:orient = (0.707, 0, 0.707, 0)\n        }\n    }\n\n    # Objects for interaction\n    def Xform "Objects"\n    {\n        def Sphere "red_ball"\n        {\n            double radius = 0.1\n            double3 xformOp:translate = (2, 1, 0.1)\n            add xformOp:orient = (0, 0, 0, 1)\n        }\n\n        def Cube "blue_box"\n        {\n            double3 size = (0.2, 0.2, 0.2)\n            double3 xformOp:translate = (-2, -1, 0.1)\n            add xformOp:orient = (0, 0, 0, 1)\n        }\n\n        def Cylinder "green_cylinder"\n        {\n            double radius = 0.1\n            double height = 0.3\n            double3 xformOp:translate = (0, 2, 0.15)\n            add xformOp:orient = (0, 0, 0, 1)\n        }\n    }\n\n    # Lighting\n    def DistantLight "sun_light"\n    {\n        float intensity = 1000\n        float3 color = (1, 1, 0.95)\n        float3 direction = (-0.5, -0.5, -1)\n        bool visible = 1\n    }\n\n    def DomeLight "dome_light"\n    {\n        float intensity = 1\n        bool visible = 1\n        string texture:file = @hdri.hdr@\n        bool texture:flipRt = 1\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h3,{id:"creating-a-domain-randomization-configuration",children:"Creating a Domain Randomization Configuration"}),"\n",(0,t.jsxs)(e.p,{children:["Create ",(0,t.jsx)(e.code,{children:"~/isaac_sim_projects/humanoid_training/domain_randomization_config.yaml"}),":"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-yaml",children:'# Domain Randomization Configuration for Humanoid Robot Training\n\nrandomization:\n  # Lighting randomization\n  lighting:\n    enabled: true\n    parameters:\n      sun_intensity_range: [500, 1500]\n      dome_intensity_range: [0.5, 1.5]\n      light_color_temperature_range: [5000, 8000]\n      light_direction_range:\n        - [0.2, 0.2, -0.9]  # Min direction\n        - [0.8, 0.8, -0.1]  # Max direction\n\n  # Material randomization\n  materials:\n    enabled: true\n    parameters:\n      albedo_range: [0.1, 1.0]  # RGB values\n      roughness_range: [0.0, 1.0]\n      metallic_range: [0.0, 0.5]\n      specular_range: [0.0, 1.0]\n\n  # Geometry randomization\n  geometry:\n    enabled: true\n    parameters:\n      object_scale_range: [0.8, 1.2]\n      object_position_jitter: [0.1, 0.1, 0.05]\n      object_rotation_range: [0, 360, 0, 360, 0, 360]  # Min/Max for X, Y, Z\n\n  # Environment randomization\n  environment:\n    enabled: true\n    parameters:\n      floor_texture_variation: 10\n      wall_color_variation: 5\n      background_objects_count: [5, 15]\n      background_object_types: ["sphere", "cube", "cylinder", "cone"]\n\n  # Sensor randomization\n  sensors:\n    enabled: true\n    parameters:\n      rgb_noise_std: [0.001, 0.01]\n      depth_noise_std: [0.001, 0.005]\n      camera_intrinsics_jitter: [0.95, 1.05]\n      camera_distortion_parameters: [-0.5, 0.5]\n\n# Data annotation settings\nannotation:\n  rgb: true\n  depth: true\n  semantic_segmentation: true\n  instance_segmentation: true\n  bounding_boxes: true\n  keypoints: true\n  pose: true\n\n# Output format settings\noutput:\n  format: "unreal_dataset"\n  resolution: [1920, 1080]\n  frame_rate: 30\n  compression: "png"\n  quality: 100\n'})}),"\n",(0,t.jsx)(e.h3,{id:"isaac-sim-python-script-for-data-generation",children:"Isaac Sim Python Script for Data Generation"}),"\n",(0,t.jsxs)(e.p,{children:["Create ",(0,t.jsx)(e.code,{children:"~/isaac_sim_projects/humanoid_training/generate_synthetic_data.py"}),":"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n\nimport omni\nfrom omni.isaac.kit import SimulationApp\nfrom omni.isaac.core import World\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\nfrom omni.isaac.core.utils.nucleus import get_assets_root_path\nfrom omni.isaac.core.utils.prims import get_prim_at_path\nfrom omni.isaac.synthetic_utils import SyntheticDataHelper\nfrom pxr import Usd, UsdGeom, Gf\nimport carb\nimport numpy as np\nimport os\nimport json\nfrom datetime import datetime\n\n# Initialize Isaac Sim\nconfig = {\n    "headless": False,\n    "render": True,\n    "width": 1920,\n    "height": 1080,\n    "experience": f"{os.environ.get(\'ISAACSIM_PATH\', \'\')}/apps/sim.default"\n}\n\nsimulation_app = SimulationApp(config)\n\n# Import necessary modules after simulation app is initialized\nfrom omni.isaac.core.utils.stage import add_reference_to_stage, get_stage_units\nfrom omni.isaac.core.utils.prims import create_prim\nfrom omni.isaac.core.prims import RigidPrim, XFormPrim\nfrom omni.isaac.core.objects import DynamicCuboid, VisualCuboid\nfrom omni.isaac.sensor import Camera\nfrom omni.isaac.core import SimulationWorld\nimport omni.replicator.core as rep\n\nclass SyntheticDataGenerator:\n    def __init__(self):\n        self.world = World(stage_units_in_meters=1.0)\n        self.scene_path = "/World"\n        self.data_output_dir = f"synthetic_data_{datetime.now().strftime(\'%Y%m%d_%H%M%S\')}"\n\n        # Create output directory\n        os.makedirs(self.data_output_dir, exist_ok=True)\n\n        # Initialize replicator for domain randomization\n        rep.orchestrator.setup()\n\n        self.setup_scene()\n        self.setup_cameras()\n        self.setup_replication()\n\n    def setup_scene(self):\n        """Set up the basic scene with humanoid robot and objects"""\n        # Add humanoid robot from USD file\n        add_reference_to_stage(\n            usd_path="scene.usd",\n            prim_path="/World/HumanoidRobot"\n        )\n\n        # Add ground plane\n        self.ground_plane = VisualCuboid(\n            prim_path="/World/ground_plane",\n            name="ground_plane",\n            position=np.array([0, 0, 0]),\n            size=np.array([20.0, 20.0, 0.1]),\n            color=np.array([0.7, 0.7, 0.7])\n        )\n\n    def setup_cameras(self):\n        """Set up cameras for data collection"""\n        # Head camera (front-facing)\n        self.head_camera = Camera(\n            prim_path="/World/HumanoidRobot/head/camera",\n            frequency=30,\n            resolution=(1920, 1080),\n            position=np.array([0.05, 0, 0.05]),\n            orientation=np.array([0, 0, 0, 1])\n        )\n\n        # Chest camera (torso-mounted)\n        self.chest_camera = Camera(\n            prim_path="/World/HumanoidRobot/torso/chest_camera",\n            frequency=30,\n            resolution=(1920, 1080),\n            position=np.array([0.1, 0, 0.3]),\n            orientation=np.array([0, 0, 0, 1])\n        )\n\n    def setup_replication(self):\n        """Set up domain randomization using Replicator"""\n        # Create a trigger that will cause randomization\n        with rep.new_layer():\n            # Randomize lighting\n            lights = rep.get.light()\n            with lights.randomize.light(intensity=(500, 1500), color=rep.distribution.color(), mode="trigger"):\n                pass\n\n            # Randomize materials\n            prims = rep.get.prims(path_pattern="/World/*")\n            with prims.randomize.material(prim_types="Sphere", mode="trigger"):\n                pass\n\n            # Randomize object positions\n            objects = rep.get.prims(path_pattern="/World/Objects/*")\n            with objects.randomize.position(\n                position=rep.distribution.uniform((-5, -5, 0.1), (5, 5, 0.1)),\n                mode="trigger"\n            ):\n                pass\n\n    def generate_data_sequence(self, num_frames=1000):\n        """Generate a sequence of synthetic data"""\n        self.world.reset()\n\n        for frame in range(num_frames):\n            # Step the world\n            self.world.step(render=True)\n\n            # Trigger randomization periodically\n            if frame % 50 == 0:\n                rep.orchestrator.run()\n\n            # Capture data from cameras\n            if frame % 10 == 0:  # Capture every 10 frames\n                self.capture_frame_data(frame)\n\n            # Move robot randomly for more diverse data\n            if frame % 20 == 0:\n                self.move_robot_randomly()\n\n        print(f"Generated {num_frames} frames of synthetic data in {self.data_output_dir}")\n\n    def capture_frame_data(self, frame_idx):\n        """Capture RGB, depth, and annotation data for current frame"""\n        # Get RGB data from head camera\n        rgb_data = self.head_camera.get_rgb()\n\n        # Get depth data\n        depth_data = self.head_camera.get_depth()\n\n        # Get segmentation data\n        seg_data = self.head_camera.get_semantic_segmentation()\n\n        # Save data to files\n        rgb_filename = f"{self.data_output_dir}/rgb_frame_{frame_idx:06d}.png"\n        depth_filename = f"{self.data_output_dir}/depth_frame_{frame_idx:06d}.npy"\n        seg_filename = f"{self.data_output_dir}/seg_frame_{frame_idx:06d}.png"\n\n        # Save data (in a real implementation, you would use appropriate libraries)\n        # np.save(depth_filename, depth_data)\n        # Save metadata\n        metadata = {\n            "frame": frame_idx,\n            "timestamp": datetime.now().isoformat(),\n            "camera_pose": self.head_camera.get_world_pose(),\n            "lighting_conditions": self.get_lighting_info(),\n            "objects_in_scene": self.get_scene_objects()\n        }\n\n        metadata_filename = f"{self.data_output_dir}/metadata_frame_{frame_idx:06d}.json"\n        with open(metadata_filename, \'w\') as f:\n            json.dump(metadata, f, indent=2)\n\n    def move_robot_randomly(self):\n        """Move robot to different positions for diverse data"""\n        # Simple random movement - in real implementation, use proper kinematics\n        robot_prim = get_prim_at_path("/World/HumanoidRobot")\n        if robot_prim.IsValid():\n            current_pos = robot_prim.GetAttribute("xformOp:translate").Get()\n            new_pos = [\n                current_pos[0] + np.random.uniform(-0.5, 0.5),\n                current_pos[1] + np.random.uniform(-0.5, 0.5),\n                current_pos[2]  # Keep same height\n            ]\n            robot_prim.GetAttribute("xformOp:translate").Set(Gf.Vec3d(*new_pos))\n\n    def get_lighting_info(self):\n        """Get current lighting conditions"""\n        # In a real implementation, query lighting parameters\n        return {\n            "sun_intensity": np.random.uniform(500, 1500),\n            "dome_intensity": np.random.uniform(0.5, 1.5),\n            "light_direction": [np.random.uniform(-1, 1) for _ in range(3)]\n        }\n\n    def get_scene_objects(self):\n        """Get information about objects in the scene"""\n        # In a real implementation, query all objects\n        return [\n            {"name": "red_ball", "type": "sphere", "position": [2, 1, 0.1]},\n            {"name": "blue_box", "type": "cube", "position": [-2, -1, 0.1]},\n            {"name": "green_cylinder", "type": "cylinder", "position": [0, 2, 0.15]}\n        ]\n\n    def cleanup(self):\n        """Clean up resources"""\n        self.world.clear()\n        simulation_app.close()\n\ndef main():\n    generator = SyntheticDataGenerator()\n\n    try:\n        print("Starting synthetic data generation...")\n        generator.generate_data_sequence(num_frames=1000)\n        print("Data generation completed successfully!")\n    except Exception as e:\n        print(f"Error during data generation: {e}")\n    finally:\n        generator.cleanup()\n\nif __name__ == "__main__":\n    main()\n'})}),"\n",(0,t.jsx)(e.h2,{id:"active-learning-exercise",children:"Active Learning Exercise"}),"\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:"Exercise: Domain Randomization Impact Analysis"})}),"\n",(0,t.jsx)(e.p,{children:"Design an experiment to evaluate the impact of different domain randomization techniques on synthetic data quality:"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Create three different scene configurations:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Minimal randomization (fixed lighting, materials, geometry)"}),"\n",(0,t.jsx)(e.li,{children:"Moderate randomization (some variation in lighting and materials)"}),"\n",(0,t.jsx)(e.li,{children:"Maximum randomization (full domain randomization)"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Generate 1000 frames of data for each configuration"}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Train a simple object detection model on each dataset"}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Evaluate the models on real-world data to compare generalization performance"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"Analyze your results to understand which randomization techniques provide the most benefit for humanoid robot perception systems."}),"\n",(0,t.jsx)(e.h2,{id:"worked-example-black-box-to-glass-box---isaac-sim-usd-scene-with-advanced-materials",children:"Worked Example: Black-box to Glass-box - Isaac Sim USD Scene with Advanced Materials"}),"\n",(0,t.jsx)(e.h3,{id:"black-box-view",children:"Black-box View"}),"\n",(0,t.jsx)(e.p,{children:"We'll create an advanced USD scene with physically-based materials and complex lighting that generates photorealistic synthetic data for humanoid robot training. The black-box view is: we provide the USD scene description, and Isaac Sim renders photorealistic images with accurate physics and lighting."}),"\n",(0,t.jsx)(e.h3,{id:"glass-box-implementation",children:"Glass-box Implementation"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:(0,t.jsx)(e.strong,{children:"Create an advanced USD scene with physically-based materials:"})}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:["Create ",(0,t.jsx)(e.code,{children:"~/isaac_sim_projects/humanoid_training/advanced_scene.usda"}),":"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-usda",children:'#usda 1.0\n\ndef Xform "World"\n{\n    # Materials Library\n    def Material "Materials/Chrome"\n    {\n        token inputs:surface.connect = </World/Materials/Chrome/PreviewSurface.outputs:surface>\n        token inputs:volume.connect = </World/Materials/Chrome/PreviewSurface.outputs:volume>\n        def Shader "PreviewSurface"\n        {\n            uniform token info:id = "UsdPreviewSurface"\n            float inputs:roughness = 0.1\n            float inputs:metallic = 1.0\n            float3 inputs:diffuseColor = (0.8, 0.8, 0.8)\n            float3 inputs:specularColor = (1.0, 1.0, 1.0)\n        }\n    }\n\n    def Material "Materials/RoughMetal"\n    {\n        token inputs:surface.connect = </World/Materials/RoughMetal/PreviewSurface.outputs:surface>\n        def Shader "PreviewSurface"\n        {\n            uniform token info:id = "UsdPreviewSurface"\n            float inputs:roughness = 0.7\n            float inputs:metallic = 0.9\n            float3 inputs:diffuseColor = (0.5, 0.5, 0.6)\n        }\n    }\n\n    def Material "Materials/Rubber"\n    {\n        token inputs:surface.connect = </World/Materials/Rubber/PreviewSurface.outputs:surface>\n        def Shader "PreviewSurface"\n        {\n            uniform token info:id = "UsdPreviewSurface"\n            float inputs:roughness = 0.9\n            float inputs:metallic = 0.0\n            float3 inputs:diffuseColor = (0.1, 0.1, 0.1)\n        }\n    }\n\n    def Material "Materials/Plastic"\n    {\n        token inputs:surface.connect = </World/Materials/Plastic/PreviewSurface.outputs:surface>\n        def Shader "PreviewSurface"\n        {\n            uniform token info:id = "UsdPreviewSurface"\n            float inputs:roughness = 0.3\n            float inputs:metallic = 0.0\n            float3 inputs:diffuseColor = (0.2, 0.6, 0.8)\n        }\n    }\n\n    # Environment\n    def Xform "Environment"\n    {\n        # Ground with advanced material\n        def Plane "ground_plane"\n        {\n            double3 extent = (50, 50)\n            rel material:binding:material = </World/Materials/RoughMetal>\n        }\n\n        # Walls with different materials\n        def Cube "wall_front"\n        {\n            double3 size = (50, 0.2, 2)\n            double3 xformOp:translate = (0, -25, 1)\n            rel material:binding:material = </World/Materials/Chrome>\n        }\n\n        def Cube "wall_back"\n        {\n            double3 size = (50, 0.2, 2)\n            double3 xformOp:translate = (0, 25, 1)\n            rel material:binding:material = </World/Materials/Plastic>\n        }\n\n        def Cube "wall_left"\n        {\n            double3 size = (0.2, 50, 2)\n            double3 xformOp:translate = (-25, 0, 1)\n            rel material:binding:material = </World/Materials/Rubber>\n        }\n\n        def Cube "wall_right"\n        {\n            double3 size = (0.2, 50, 2)\n            double3 xformOp:translate = (25, 0, 1)\n            rel material:binding:material = </World/Materials/Chrome>\n        }\n    }\n\n    # Humanoid Robot with detailed materials\n    def Xform "HumanoidRobot"\n    {\n        double3 xformOp:translate = (0, 0, 1.0)\n\n        # Torso with metallic material\n        def Capsule "torso"\n        {\n            double radius = 0.15\n            double height = 0.6\n            double3 xformOp:translate = (0, 0, 0.6)\n            add xformOp:orient = (0.707, 0, 0.707, 0)\n            rel material:binding:material = </World/Materials/Chrome>\n        }\n\n        # Head with plastic material\n        def Sphere "head"\n        {\n            double radius = 0.12\n            double3 xformOp:translate = (0, 0, 1.0)\n            rel material:binding:material = </World/Materials/Plastic>\n        }\n\n        # Arms with rubber material\n        def Capsule "left_upper_arm"\n        {\n            double radius = 0.05\n            double height = 0.4\n            double3 xformOp:translate = (0.25, 0.15, 0.6)\n            add xformOp:orient = (0.707, 0, 0.707, 0)\n            rel material:binding:material = </World/Materials/Rubber>\n        }\n\n        def Capsule "left_lower_arm"\n        {\n            double radius = 0.04\n            double height = 0.35\n            double3 xformOp:translate = (0.25, 0.15, 0.25)\n            add xformOp:orient = (0.707, 0, 0.707, 0)\n            rel material:binding:material = </World/Materials/Rubber>\n        }\n\n        def Capsule "right_upper_arm"\n        {\n            double radius = 0.05\n            double height = 0.4\n            double3 xformOp:translate = (0.25, -0.15, 0.6)\n            add xformOp:orient = (0.707, 0, 0.707, 0)\n            rel material:binding:material = </World/Materials/Rubber>\n        }\n\n        def Capsule "right_lower_arm"\n        {\n            double radius = 0.04\n            double height = 0.35\n            double3 xformOp:translate = (0.25, -0.15, 0.25)\n            add xformOp:orient = (0.707, 0, 0.707, 0)\n            rel material:binding:material = </World/Materials/Rubber>\n        }\n\n        # Legs with chrome material\n        def Capsule "left_upper_leg"\n        {\n            double radius = 0.08\n            double height = 0.5\n            double3 xformOp:translate = (-0.1, 0.1, -0.1)\n            add xformOp:orient = (0.707, 0, 0.707, 0)\n            rel material:binding:material = </World/Materials/Chrome>\n        }\n\n        def Capsule "left_lower_leg"\n        {\n            double radius = 0.07\n            double height = 0.45\n            double3 xformOp:translate = (-0.1, 0.1, -0.6)\n            add xformOp:orient = (0.707, 0, 0.707, 0)\n            rel material:binding:material = </World/Materials/Chrome>\n        }\n\n        def Capsule "right_upper_leg"\n        {\n            double radius = 0.08\n            double height = 0.5\n            double3 xformOp:translate = (-0.1, -0.1, -0.1)\n            add xformOp:orient = (0.707, 0, 0.707, 0)\n            rel material:binding:material = </World/Materials/Chrome>\n        }\n\n        def Capsule "right_lower_leg"\n        {\n            double radius = 0.07\n            double height = 0.45\n            double3 xformOp:translate = (-0.1, -0.1, -0.6)\n            add xformOp:orient = (0.707, 0, 0.707, 0)\n            rel material:binding:material = </World/Materials/Chrome>\n        }\n    }\n\n    # Interactive objects with varied materials\n    def Xform "Objects"\n    {\n        def Sphere "chrome_ball"\n        {\n            double radius = 0.1\n            double3 xformOp:translate = (2, 1, 0.1)\n            rel material:binding:material = </World/Materials/Chrome>\n        }\n\n        def Cube "rubber_cube"\n        {\n            double3 size = (0.2, 0.2, 0.2)\n            double3 xformOp:translate = (-2, -1, 0.1)\n            rel material:binding:material = </World/Materials/Rubber>\n        }\n\n        def Cylinder "plastic_cylinder"\n        {\n            double radius = 0.1\n            double height = 0.3\n            double3 xformOp:translate = (0, 2, 0.15)\n            rel material:binding:material = </World/Materials/Plastic>\n        }\n\n        def Cone "metal_cone"\n        {\n            double radius = 0.1\n            double height = 0.3\n            double3 xformOp:translate = (3, -2, 0.15)\n            rel material:binding:material = </World/Materials/RoughMetal>\n        }\n    }\n\n    # Advanced lighting setup\n    def DistantLight "sun_light"\n    {\n        float intensity = 1000\n        float3 color = (1, 0.95, 0.9)\n        float3 direction = (-0.3, -0.3, -0.9)\n        bool visible = 1\n    }\n\n    def DomeLight "dome_light"\n    {\n        float intensity = 1.5\n        bool visible = 0\n        string texture:file = @sky_hdri.exr@\n        bool texture:flipRt = 1\n    }\n\n    # Additional point lights for fill lighting\n    def SphereLight "fill_light_1"\n    {\n        float intensity = 300\n        float3 color = (0.9, 0.95, 1.0)\n        double3 xformOp:translate = (5, 5, 3)\n        bool visible = 0\n    }\n\n    def SphereLight "fill_light_2"\n    {\n        float intensity = 300\n        float3 color = (1.0, 0.95, 0.9)\n        double3 xformOp:translate = (-5, -5, 3)\n        bool visible = 0\n    }\n}\n'})}),"\n",(0,t.jsxs)(e.ol,{start:"2",children:["\n",(0,t.jsx)(e.li,{children:(0,t.jsx)(e.strong,{children:"Create a domain randomization script:"})}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:["Create ",(0,t.jsx)(e.code,{children:"~/isaac_sim_projects/humanoid_training/domain_randomization.py"}),":"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n\nimport omni.replicator.core as rep\nimport numpy as np\n\nclass DomainRandomizer:\n    def __init__(self):\n        rep.orchestrator.setup()\n        self.setup_randomization()\n\n    def setup_randomization(self):\n        """Set up domain randomization for the scene"""\n        with rep.new_layer():\n            # Randomize lighting\n            lights = rep.get.light()\n\n            # Randomize distant light (sun)\n            with lights.randomize.light(\n                intensity=rep.distribution.normal(1000, 200),\n                color=rep.distribution.uniform((0.8, 0.8, 0.8), (1.0, 1.0, 1.0)),\n                position=rep.distribution.uniform((-1, -1, -1), (1, 1, -0.5)),\n                look_at=rep.distribution.uniform((-5, -5, 0), (5, 5, 2)),\n                mode="trigger"\n            ):\n                pass\n\n            # Randomize dome light\n            with lights.randomize.light(\n                prim_types="DomeLight",\n                intensity=rep.distribution.uniform(0.5, 2.0),\n                texture_file=rep.distribution.choice([\n                    "sky_hdri_1.exr", "sky_hdri_2.exr", "sky_hdri_3.exr"\n                ]),\n                mode="trigger"\n            ):\n                pass\n\n            # Randomize materials\n            prims = rep.get.prims(path_pattern="/World/Environment/*")\n            with prims.randomize.material(\n                roughness=rep.distribution.uniform(0.1, 0.9),\n                metallic=rep.distribution.uniform(0.0, 1.0),\n                diffuse_color=rep.distribution.uniform((0.1, 0.1, 0.1), (1.0, 1.0, 1.0)),\n                mode="trigger"\n            ):\n                pass\n\n            # Randomize object positions and properties\n            objects = rep.get.prims(path_pattern="/World/Objects/*")\n            with objects.randomize.position(\n                position=rep.distribution.uniform((-8, -8, 0.1), (8, 8, 0.1)),\n                mode="trigger"\n            ):\n                pass\n\n            with objects.randomize.scale(\n                scale=rep.distribution.uniform((0.5, 0.5, 0.5), (1.5, 1.5, 1.5)),\n                mode="trigger"\n            ):\n                pass\n\n            # Randomize robot position and orientation\n            robot_parts = rep.get.prims(path_pattern="/World/HumanoidRobot/*")\n            with robot_parts.randomize.position(\n                position=rep.distribution.uniform((-2, -2, 1.0), (2, 2, 1.0)),\n                mode="trigger"\n            ):\n                pass\n\n            # Randomize textures\n            materials = rep.get.material()\n            with materials.randomize.material(\n                prim_types="Shader",\n                inputs_roughness=rep.distribution.uniform(0.0, 1.0),\n                inputs_metallic=rep.distribution.uniform(0.0, 1.0),\n                inputs_diffuseColor=rep.distribution.uniform((0.0, 0.0, 0.0), (1.0, 1.0, 1.0)),\n                mode="trigger"\n            ):\n                pass\n\n    def run_randomization(self):\n        """Trigger the domain randomization"""\n        rep.orchestrator.run()\n\n    def get_randomization_summary(self):\n        """Get summary of randomization parameters"""\n        return {\n            "lighting_randomization": True,\n            "material_randomization": True,\n            "geometry_randomization": True,\n            "object_randomization": True,\n            "robot_randomization": True\n        }\n\ndef main():\n    randomizer = DomainRandomizer()\n    print("Domain randomization setup complete")\n    print("Randomization summary:", randomizer.get_randomization_summary())\n\n    # In a real implementation, you would call this periodically during data generation\n    # randomizer.run_randomization()\n\nif __name__ == "__main__":\n    main()\n'})}),"\n",(0,t.jsx)(e.h3,{id:"understanding-the-implementation",children:"Understanding the Implementation"}),"\n",(0,t.jsx)(e.p,{children:"The glass-box view reveals:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"The USD scene defines complex materials using the Physically-Based Rendering (PBR) pipeline"}),"\n",(0,t.jsx)(e.li,{children:"Domain randomization uses NVIDIA's Replicator framework to introduce variations in lighting, materials, and geometry"}),"\n",(0,t.jsx)(e.li,{children:"The system can generate diverse synthetic data that improves model generalization"}),"\n",(0,t.jsx)(e.li,{children:"The implementation includes proper material bindings and physically accurate properties"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"tiered-assessments",children:"Tiered Assessments"}),"\n",(0,t.jsx)(e.h3,{id:"tier-1-basic-understanding",children:"Tier 1: Basic Understanding"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"What is Universal Scene Description (USD) and why is it important for Isaac Sim?"}),"\n",(0,t.jsx)(e.li,{children:"Name three types of domain randomization techniques."}),"\n",(0,t.jsx)(e.li,{children:"What is the purpose of physically-based rendering in synthetic data generation?"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"tier-2-application",children:"Tier 2: Application"}),"\n",(0,t.jsxs)(e.ol,{start:"4",children:["\n",(0,t.jsx)(e.li,{children:"Create a USD scene with a humanoid robot and multiple objects for synthetic data generation."}),"\n",(0,t.jsx)(e.li,{children:"Implement domain randomization for lighting and material properties in Isaac Sim."}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"tier-3-analysis-and-synthesis",children:"Tier 3: Analysis and Synthesis"}),"\n",(0,t.jsxs)(e.ol,{start:"6",children:["\n",(0,t.jsx)(e.li,{children:"Design a complete synthetic data generation pipeline for humanoid robot perception that includes domain randomization, automated annotation, and quality validation."}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"mermaid-diagram",children:"Mermaid Diagram"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-mermaid",children:"graph TB\n    A[Real World Data] --\x3e B[Data Bottleneck]\n    C[Isaac Sim] --\x3e D[USD Scene]\n    C --\x3e E[Domain Randomization]\n    C --\x3e F[Physically-Based Rendering]\n\n    D --\x3e G[Humanoid Robot Model]\n    D --\x3e H[Environment Setup]\n    D --\x3e I[Lighting Configuration]\n\n    E --\x3e J[Material Variation]\n    E --\x3e K[Geometry Variation]\n    E --\x3e L[Lighting Variation]\n\n    F --\x3e M[Photorealistic Images]\n    F --\x3e N[Accurate Physics]\n\n    G --\x3e O[Synthetic Dataset]\n    H --\x3e O\n    J --\x3e O\n    K --\x3e O\n    L --\x3e O\n    M --\x3e O\n\n    O --\x3e P[Deep Learning Training]\n    P --\x3e Q[Real Robot Deployment]\n\n    style A fill:#ff9999\n    style C fill:#99ccff\n    style O fill:#99ff99\n    style Q fill:#ffcc99\n"})}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Alt-text for diagram:"}),' "Synthetic data generation pipeline showing how real world data faces a data bottleneck, while Isaac Sim provides solutions through USD scenes, domain randomization, and physically-based rendering. The USD scene includes humanoid robot model, environment setup, and lighting configuration. Domain randomization includes material, geometry, and lighting variations. Physically-based rendering provides photorealistic images and accurate physics. All components contribute to creating a synthetic dataset that feeds into deep learning training and real robot deployment. Real world data is highlighted in pink, Isaac Sim in light blue, synthetic dataset in light green, and robot deployment in light orange."']}),"\n",(0,t.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(e.p,{children:"This chapter introduced the fundamentals of synthetic data generation using NVIDIA Isaac Sim for humanoid robotics applications. We explored the Universal Scene Description framework, domain randomization techniques, and physically-based rendering that enable the creation of photorealistic synthetic datasets. Through practical examples, we demonstrated how to create complex USD scenes and implement domain randomization to improve model generalization for robot perception systems."}),"\n",(0,t.jsx)(e.h2,{id:"references",children:"References"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"NVIDIA. (2022). NVIDIA Isaac Sim: Developer Guide. NVIDIA Corporation."}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"NVIDIA. (2021). Domain Randomization in Isaac Sim. NVIDIA Developer Documentation."}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:["Tobin, J., Fong, R., Ray, A., Schneider, J., Zaremba, W., & Abbeel, P. (2017). Domain randomization for transferring deep neural networks from simulation to the real world. ",(0,t.jsx)(e.em,{children:"2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)"}),", 23-30."]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:["Sadeghi, F., & Levine, S. (2017). CAD2RL: Real single-image flight without a single real image. ",(0,t.jsx)(e.em,{children:"Proceedings of the 1st Annual Conference on Robot Learning"}),", 209-219."]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:["James, S., Davison, A. J., & Johns, E. (2019). Translating images across domains for real-world robot navigation. ",(0,t.jsx)(e.em,{children:"2019 International Conference on Robotics and Automation (ICRA)"}),", 5399-5405."]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:["Filipov, E., Gao, J., Chen, X., Bai, S., & Fuchs, H. (2018). DARP: Disagreement-regularized domain adaptation for sim-to-real transfer. ",(0,t.jsx)(e.em,{children:"arXiv preprint arXiv:1811.09305"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:["Peng, X. B., Andry, P., Zhang, E., Abbeel, P., & Dragan, A. (2018). Sim-to-real transfer of robotic control with dynamics randomization. ",(0,t.jsx)(e.em,{children:"2018 IEEE International Conference on Robotics and Automation (ICRA)"}),", 1-8."]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:["Sadeghi, F., Eitel, F., & Levine, S. (2018). High precision simulated depth images through differentiable rendering. ",(0,t.jsx)(e.em,{children:"2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)"}),", 2830-2837."]}),"\n"]}),"\n"]})]})}function c(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(m,{...n})}):m(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>o,x:()=>s});var a=i(6540);const t={},r=a.createContext(t);function o(n){const e=a.useContext(r);return a.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:o(n.components),a.createElement(r.Provider,{value:e},n.children)}}}]);