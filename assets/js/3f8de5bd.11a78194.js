"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[760],{411:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>m,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"ros2/nodes-topics-services-actions","title":"Nodes, Topics, Services, and Actions","description":"Learning Objectives","source":"@site/docs/01-ros2/02-nodes-topics-services-actions.md","sourceDirName":"01-ros2","slug":"/ros2/nodes-topics-services-actions","permalink":"/ros2/nodes-topics-services-actions","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/01-ros2/02-nodes-topics-services-actions.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Nodes, Topics, Services, and Actions"},"sidebar":"moduleSidebar","previous":{"title":"ROS 2 and Embodied Control","permalink":"/ros2/ros2-and-embodied-control"},"next":{"title":"URDF + Xacro for Humanoids","permalink":"/ros2/urdf-xacro-for-humanoids"}}');var a=i(4848),t=i(8453);const o={sidebar_position:2,title:"Nodes, Topics, Services, and Actions"},r="Nodes, Topics, Services, and Actions",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction",id:"introduction",level:2},{value:"Theory: Communication Patterns in ROS 2",id:"theory-communication-patterns-in-ros-2",level:2},{value:"Nodes",id:"nodes",level:3},{value:"Topics (Publish/Subscribe)",id:"topics-publishsubscribe",level:3},{value:"Services (Request/Reply)",id:"services-requestreply",level:3},{value:"Actions (Goal-Based with Feedback)",id:"actions-goal-based-with-feedback",level:3},{value:"Practice: Implementing Communication Patterns",id:"practice-implementing-communication-patterns",level:2},{value:"Creating a Multi-Interface Node",id:"creating-a-multi-interface-node",level:3},{value:"Topic Publisher: Head Pose",id:"topic-publisher-head-pose",level:3},{value:"Service Server: Head Calibration",id:"service-server-head-calibration",level:3},{value:"Action Server: Head Tracking",id:"action-server-head-tracking",level:3},{value:"Active Learning Exercise",id:"active-learning-exercise",level:2},{value:"Worked Example: Black-box to Glass-box - Implementing a Humanoid Action Server",id:"worked-example-black-box-to-glass-box---implementing-a-humanoid-action-server",level:2},{value:"Black-box View",id:"black-box-view",level:3},{value:"Glass-box Implementation",id:"glass-box-implementation",level:3},{value:"Understanding the Implementation",id:"understanding-the-implementation",level:3},{value:"Tiered Assessments",id:"tiered-assessments",level:2},{value:"Tier 1: Basic Understanding",id:"tier-1-basic-understanding",level:3},{value:"Tier 2: Application",id:"tier-2-application",level:3},{value:"Tier 3: Analysis and Synthesis",id:"tier-3-analysis-and-synthesis",level:3},{value:"Mermaid Diagram",id:"mermaid-diagram",level:2},{value:"Summary",id:"summary",level:2},{value:"References",id:"references",level:2}];function d(e){const n={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"nodes-topics-services-and-actions",children:"Nodes, Topics, Services, and Actions"})}),"\n",(0,a.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,a.jsx)(n.p,{children:"By the end of this chapter, students will be able to:"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Distinguish between the four primary communication patterns in ROS 2 (topics, services, actions)"}),"\n",(0,a.jsx)(n.li,{children:"Design appropriate communication patterns for different humanoid robot subsystems"}),"\n",(0,a.jsx)(n.li,{children:"Implement ROS 2 nodes with multiple communication interfaces"}),"\n",(0,a.jsx)(n.li,{children:"Create custom message, service, and action definition files"}),"\n",(0,a.jsx)(n.li,{children:"Configure Quality of Service (QoS) settings for different communication needs"}),"\n",(0,a.jsx)(n.li,{children:"Debug communication issues between ROS 2 nodes"}),"\n",(0,a.jsx)(n.li,{children:"Evaluate the trade-offs between different communication patterns for real-time control"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,a.jsx)(n.p,{children:"ROS 2 provides four distinct communication patterns that serve different purposes in robotic systems: topics (publish/subscribe), services (request/reply), actions (goal-based with feedback), and parameters (configuration). Understanding when and how to use each pattern is crucial for effective humanoid robot design, where timing constraints, reliability requirements, and real-time performance vary significantly across subsystems."}),"\n",(0,a.jsx)(n.p,{children:"In humanoid robotics, these communication patterns work together to enable complex behaviors. For example, sensor data streams use topics for continuous updates, while goal-oriented tasks like walking use actions that provide feedback and can be preempted. Service calls might be used for calibration routines that require guaranteed delivery and response."}),"\n",(0,a.jsx)(n.h2,{id:"theory-communication-patterns-in-ros-2",children:"Theory: Communication Patterns in ROS 2"}),"\n",(0,a.jsx)(n.h3,{id:"nodes",children:"Nodes"}),"\n",(0,a.jsx)(n.p,{children:"A node is the fundamental execution unit in ROS 2. Each node represents a process that performs computation. In humanoid robots, nodes might represent joint controllers, sensor drivers, perception algorithms, or motion planners. Nodes can contain multiple publishers, subscribers, services, and action servers/clients."}),"\n",(0,a.jsx)(n.h3,{id:"topics-publishsubscribe",children:"Topics (Publish/Subscribe)"}),"\n",(0,a.jsx)(n.p,{children:"Topics provide asynchronous, many-to-many communication. Publishers send messages to topics, and subscribers receive messages from topics. This pattern is ideal for sensor data streams, joint states, and other continuous data flows. Topics are fire-and-forget, meaning publishers don't know if anyone is listening."}),"\n",(0,a.jsx)(n.h3,{id:"services-requestreply",children:"Services (Request/Reply)"}),"\n",(0,a.jsx)(n.p,{children:"Services provide synchronous, request-response communication. A client sends a request and waits for a response. This pattern is appropriate for operations that have a clear beginning and end, such as calibration, configuration changes, or computational tasks with guaranteed completion."}),"\n",(0,a.jsx)(n.h3,{id:"actions-goal-based-with-feedback",children:"Actions (Goal-Based with Feedback)"}),"\n",(0,a.jsx)(n.p,{children:"Actions provide asynchronous, goal-based communication with feedback. They're designed for long-running tasks that might take time to complete, with the ability to provide ongoing feedback and be preempted. This is ideal for navigation, manipulation, or locomotion tasks in humanoid robots."}),"\n",(0,a.jsx)(n.h2,{id:"practice-implementing-communication-patterns",children:"Practice: Implementing Communication Patterns"}),"\n",(0,a.jsx)(n.h3,{id:"creating-a-multi-interface-node",children:"Creating a Multi-Interface Node"}),"\n",(0,a.jsx)(n.p,{children:"Let's create a node that demonstrates all three communication patterns for a humanoid robot's head subsystem:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"cd ~/ros2_ws/src\nros2 pkg create --build-type ament_python head_control_node --dependencies rclpy std_msgs sensor_msgs geometry_msgs action_msgs\n"})}),"\n",(0,a.jsx)(n.h3,{id:"topic-publisher-head-pose",children:"Topic Publisher: Head Pose"}),"\n",(0,a.jsxs)(n.p,{children:["Create ",(0,a.jsx)(n.code,{children:"~/ros2_ws/src/head_control_node/head_control_node/head_pose_publisher.py"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import PoseStamped\nfrom std_msgs.msg import Header\nimport math\nimport time\n\nclass HeadPosePublisher(Node):\n    def __init__(self):\n        super().__init__('head_pose_publisher')\n\n        # Create publisher for head pose\n        self.publisher_ = self.create_publisher(PoseStamped, 'head_pose', 10)\n\n        # Timer for publishing messages\n        timer_period = 0.05  # 20Hz\n        self.timer = self.create_timer(timer_period, self.timer_callback)\n\n        self.time = 0.0\n\n    def timer_callback(self):\n        msg = PoseStamped()\n        msg.header = Header()\n        msg.header.stamp = self.get_clock().now().to_msg()\n        msg.header.frame_id = \"base_link\"\n\n        # Simulate head looking around\n        msg.pose.position.x = 0.0\n        msg.pose.position.y = 0.0\n        msg.pose.position.z = 1.7  # Height of head\n\n        # Simulate head rotation\n        msg.pose.orientation.w = math.cos(self.time * 0.1)\n        msg.pose.orientation.x = 0.0\n        msg.pose.orientation.y = math.sin(self.time * 0.1)\n        msg.pose.orientation.z = 0.0\n\n        self.publisher_.publish(msg)\n        self.get_logger().info(f'Head pose published: ({msg.pose.position.x}, {msg.pose.position.y}, {msg.pose.position.z})')\n\n        self.time += timer_period\n\ndef main(args=None):\n    rclpy.init(args=args)\n    head_pose_publisher = HeadPosePublisher()\n\n    try:\n        rclpy.spin(head_pose_publisher)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        head_pose_publisher.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(n.h3,{id:"service-server-head-calibration",children:"Service Server: Head Calibration"}),"\n",(0,a.jsxs)(n.p,{children:["Create ",(0,a.jsx)(n.code,{children:"~/ros2_ws/src/head_control_node/head_control_node/head_calibration_service.py"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.node import Node\nfrom rclpy.qos import QoSProfile\nfrom example_interfaces.srv import Trigger\n\nclass HeadCalibrationService(Node):\n    def __init__(self):\n        super().__init__('head_calibration_service')\n\n        # Create service server\n        self.srv = self.create_service(Trigger, 'head_calibration', self.calibrate_head_callback)\n\n        self.calibration_complete = False\n\n    def calibrate_head_callback(self, request, response):\n        self.get_logger().info('Starting head calibration...')\n\n        # Simulate calibration process\n        import time\n        time.sleep(2)  # Simulate actual calibration time\n\n        self.calibration_complete = True\n        response.success = True\n        response.message = 'Head calibration completed successfully'\n\n        self.get_logger().info('Head calibration finished')\n        return response\n\ndef main(args=None):\n    rclpy.init(args=args)\n    head_calibration_service = HeadCalibrationService()\n\n    try:\n        rclpy.spin(head_calibration_service)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        head_calibration_service.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(n.h3,{id:"action-server-head-tracking",children:"Action Server: Head Tracking"}),"\n",(0,a.jsxs)(n.p,{children:["Create ",(0,a.jsx)(n.code,{children:"~/ros2_ws/src/head_control_node/head_control_node/head_tracking_action.py"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.action import ActionServer\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Point\n\n# Using a simple goal-based action for head tracking\nfrom example_interfaces.action import FollowJointTrajectory\n\nclass HeadTrackingActionServer(Node):\n    def __init__(self):\n        super().__init__('head_tracking_action_server')\n\n        # Create action server\n        self._action_server = ActionServer(\n            self,\n            FollowJointTrajectory,\n            'head_tracking',\n            self.execute_callback)\n\n    def execute_callback(self, goal_handle):\n        self.get_logger().info('Executing head tracking goal...')\n\n        # Get target position from goal\n        target_point = goal_handle.request.trajectory.points[0].positions\n\n        # Simulate tracking\n        feedback_msg = FollowJointTrajectory.Feedback()\n\n        for i in range(0, 100):\n            # Simulate moving toward target\n            feedback_msg.joint_names = ['head_pan', 'head_tilt']\n            feedback_msg.actual.positions = [target_point[0] * i / 100, target_point[1] * i / 100]\n\n            goal_handle.publish_feedback(feedback_msg)\n\n            # Check if goal was canceled\n            if goal_handle.is_cancel_requested:\n                goal_handle.canceled()\n                self.get_logger().info('Head tracking goal canceled')\n                return FollowJointTrajectory.Result()\n\n            # Sleep to simulate real movement\n            from time import sleep\n            sleep(0.05)\n\n        # Complete the goal\n        goal_handle.succeed()\n\n        result = FollowJointTrajectory.Result()\n        result.error_code = 0  # SUCCESS\n        self.get_logger().info('Head tracking goal succeeded')\n\n        return result\n\ndef main(args=None):\n    rclpy.init(args=args)\n    head_tracking_action_server = HeadTrackingActionServer()\n\n    try:\n        rclpy.spin(head_tracking_action_server)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        head_tracking_action_server.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(n.h2,{id:"active-learning-exercise",children:"Active Learning Exercise"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Exercise: Communication Pattern Selection"})}),"\n",(0,a.jsx)(n.p,{children:"Consider the following humanoid robot subsystems:"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"IMU sensor data publishing"}),"\n",(0,a.jsx)(n.li,{children:"Walking pattern generation"}),"\n",(0,a.jsx)(n.li,{children:"Emergency stop service"}),"\n",(0,a.jsx)(n.li,{children:"Joint position control"}),"\n",(0,a.jsx)(n.li,{children:"Vision-based object detection"}),"\n",(0,a.jsx)(n.li,{children:"Path planning"}),"\n",(0,a.jsx)(n.li,{children:"Battery status monitoring"}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"For each subsystem, determine which communication pattern(s) would be most appropriate and justify your choice considering:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Frequency of communication"}),"\n",(0,a.jsx)(n.li,{children:"Need for guaranteed delivery"}),"\n",(0,a.jsx)(n.li,{children:"Real-time constraints"}),"\n",(0,a.jsx)(n.li,{children:"Ability to be preempted"}),"\n",(0,a.jsx)(n.li,{children:"Feedback requirements"}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"Discuss your choices with a partner and compare different approaches to the same subsystems."}),"\n",(0,a.jsx)(n.h2,{id:"worked-example-black-box-to-glass-box---implementing-a-humanoid-action-server",children:"Worked Example: Black-box to Glass-box - Implementing a Humanoid Action Server"}),"\n",(0,a.jsx)(n.h3,{id:"black-box-view",children:"Black-box View"}),"\n",(0,a.jsx)(n.p,{children:'We\'ll implement an action server for humanoid walking. The black-box view is: a client sends a walking goal (e.g., "walk 2 meters forward"), the server executes the walking pattern, provides feedback on progress, and reports success or failure.'}),"\n",(0,a.jsx)(n.h3,{id:"glass-box-implementation",children:"Glass-box Implementation"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.strong,{children:"Create custom action definition:"})}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"First, create a custom action definition for humanoid walking:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"mkdir -p ~/ros2_ws/src/humanoid_actions/humanoid_actions/action\n"})}),"\n",(0,a.jsxs)(n.p,{children:["Create ",(0,a.jsx)(n.code,{children:"~/ros2_ws/src/humanoid_actions/humanoid_actions/action/HumanoidWalk.action"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"# Goal: Specify where to walk to\ngeometry_msgs/Point target_position\nfloat64 step_size\nint32 step_count\n\n---\n# Result: Outcome of the walk\nbool success\nstring message\nfloat64 actual_distance\n\n---\n# Feedback: Current progress\nfloat64 distance_traveled\nint32 steps_completed\ngeometry_msgs/Point current_position\n"})}),"\n",(0,a.jsxs)(n.ol,{start:"2",children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.strong,{children:"Update package.xml to include action_msgs dependency:"})}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-xml",children:"<depend>action_msgs</depend>\n<depend>geometry_msgs</depend>\n<build_depend>rosidl_default_generators</build_depend>\n<exec_depend>rosidl_default_runtime</exec_depend>\n<member_of_group>rosidl_interface_packages</member_of_group>\n"})}),"\n",(0,a.jsxs)(n.ol,{start:"3",children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.strong,{children:"Create the action server:"})}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["Create ",(0,a.jsx)(n.code,{children:"~/ros2_ws/src/humanoid_actions/humanoid_actions/walk_action_server.py"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.action import ActionServer, CancelResponse\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Point\nfrom rclpy.qos import QoSProfile\nfrom humanoid_actions.action import HumanoidWalk\n\nclass HumanoidWalkActionServer(Node):\n    def __init__(self):\n        super().__init__('humanoid_walk_action_server')\n\n        # Create action server with custom callback for cancellation\n        self._action_server = ActionServer(\n            self,\n            HumanoidWalk,\n            'humanoid_walk',\n            self.execute_callback,\n            cancel_callback=self.cancel_callback)\n\n        # Initialize current position\n        self.current_position = Point(x=0.0, y=0.0, z=0.0)\n\n    def cancel_callback(self, goal_handle):\n        \"\"\"Allow cancellation of the walking goal\"\"\"\n        self.get_logger().info('Received request to cancel walking goal')\n        return CancelResponse.ACCEPT\n\n    def execute_callback(self, goal_handle):\n        \"\"\"Execute the walking goal\"\"\"\n        self.get_logger().info('Executing walking goal...')\n\n        # Get goal parameters\n        target_position = goal_handle.request.target_position\n        step_size = goal_handle.request.step_size\n        step_count = goal_handle.request.step_count\n\n        # Initialize feedback\n        feedback_msg = HumanoidWalk.Feedback()\n        feedback_msg.distance_traveled = 0.0\n        feedback_msg.steps_completed = 0\n        feedback_msg.current_position = self.current_position\n\n        # Simulate walking process\n        for step in range(step_count):\n            # Check if goal was canceled\n            if goal_handle.is_cancel_requested:\n                goal_handle.canceled()\n                self.get_logger().info('Walking goal canceled')\n\n                result = HumanoidWalk.Result()\n                result.success = False\n                result.message = 'Goal canceled by user'\n                result.actual_distance = feedback_msg.distance_traveled\n                return result\n\n            # Update position based on step\n            self.current_position.x += step_size\n            feedback_msg.distance_traveled = self.current_position.x\n            feedback_msg.steps_completed = step + 1\n            feedback_msg.current_position = self.current_position\n\n            # Publish feedback\n            goal_handle.publish_feedback(feedback_msg)\n\n            self.get_logger().info(f'Step {step + 1}/{step_count}, Distance: {feedback_msg.distance_traveled:.2f}m')\n\n            # Simulate time for each step\n            from time import sleep\n            sleep(0.5)\n\n        # Complete the goal successfully\n        goal_handle.succeed()\n\n        result = HumanoidWalk.Result()\n        result.success = True\n        result.message = f'Walked successfully to target position: ({target_position.x}, {target_position.y}, {target_position.z})'\n        result.actual_distance = feedback_msg.distance_traveled\n\n        self.get_logger().info(f'Walking goal completed. Traveled {result.actual_distance:.2f} meters')\n        return result\n\ndef main(args=None):\n    rclpy.init(args=args)\n    humanoid_walk_action_server = HumanoidWalkActionServer()\n\n    try:\n        rclpy.spin(humanoid_walk_action_server)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        humanoid_walk_action_server.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsxs)(n.ol,{start:"4",children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.strong,{children:"Create the action client:"})}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["Create ",(0,a.jsx)(n.code,{children:"~/ros2_ws/src/humanoid_actions/humanoid_actions/walk_action_client.py"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.action import ActionClient\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Point\nfrom humanoid_actions.action import HumanoidWalk\n\nclass HumanoidWalkActionClient(Node):\n    def __init__(self):\n        super().__init__('humanoid_walk_action_client')\n        self._action_client = ActionClient(self, HumanoidWalk, 'humanoid_walk')\n\n    def send_goal(self, target_x=2.0, step_size=0.1, step_count=20):\n        # Wait for action server\n        self._action_client.wait_for_server()\n\n        # Create goal\n        goal_msg = HumanoidWalk.Goal()\n        goal_msg.target_position = Point(x=target_x, y=0.0, z=0.0)\n        goal_msg.step_size = step_size\n        goal_msg.step_count = step_count\n\n        # Send goal\n        self._send_goal_future = self._action_client.send_goal_async(\n            goal_msg,\n            feedback_callback=self.feedback_callback)\n\n        self._send_goal_future.add_done_callback(self.goal_response_callback)\n\n    def goal_response_callback(self, future):\n        goal_handle = future.result()\n        if not goal_handle.accepted:\n            self.get_logger().info('Goal rejected :(')\n            return\n\n        self.get_logger().info('Goal accepted :)')\n\n        self._get_result_future = goal_handle.get_result_async()\n        self._get_result_future.add_done_callback(self.get_result_callback)\n\n    def feedback_callback(self, feedback_msg):\n        feedback = feedback_msg.feedback\n        self.get_logger().info(\n            f'Feedback: {feedback.distance_traveled:.2f}m traveled, '\n            f'{feedback.steps_completed} steps completed')\n\n    def get_result_callback(self, future):\n        result = future.result().result\n        self.get_logger().info(f'Result: {result.message}')\n        rclpy.shutdown()\n\ndef main(args=None):\n    rclpy.init(args=args)\n    action_client = HumanoidWalkActionClient()\n\n    # Send a goal to walk 2 meters forward\n    action_client.send_goal(target_x=2.0, step_size=0.1, step_count=20)\n\n    rclpy.spin(action_client)\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsxs)(n.ol,{start:"5",children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.strong,{children:"Update setup.py to include action interfaces:"})}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from setuptools import find_packages, setup\nimport os\nfrom glob import glob\n\npackage_name = 'humanoid_actions'\n\nsetup(\n    name=package_name,\n    version='0.0.0',\n    packages=find_packages(exclude=['test']),\n    data_files=[\n        ('share/ament_index/resource_index/packages',\n            ['resource/' + package_name]),\n        ('share/' + package_name, ['package.xml']),\n        ('share/' + package_name + '/action', glob('humanoid_actions/action/*.action')),\n    ],\n    install_requires=['setuptools'],\n    zip_safe=True,\n    maintainer='your_name',\n    maintainer_email='your_email@example.com',\n    description='Action definitions for humanoid robot walking',\n    license='Apache-2.0',\n    tests_require=['pytest'],\n    entry_points={\n        'console_scripts': [\n            'walk_action_server = humanoid_actions.walk_action_server:main',\n            'walk_action_client = humanoid_actions.walk_action_client:main',\n        ],\n    },\n)\n"})}),"\n",(0,a.jsxs)(n.ol,{start:"6",children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.strong,{children:"Build the package:"})}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"cd ~/ros2_ws\ncolcon build --packages-select humanoid_actions\nsource install/setup.bash\n"})}),"\n",(0,a.jsx)(n.h3,{id:"understanding-the-implementation",children:"Understanding the Implementation"}),"\n",(0,a.jsx)(n.p,{children:"The glass-box view reveals:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"The action server implements the three-part communication: goal, feedback, result"}),"\n",(0,a.jsx)(n.li,{children:"The server can be canceled mid-execution, which is important for safety in humanoid robots"}),"\n",(0,a.jsx)(n.li,{children:"Feedback is continuously sent to update the client on progress"}),"\n",(0,a.jsx)(n.li,{children:"The implementation includes proper error handling and state management"}),"\n",(0,a.jsx)(n.li,{children:"The client handles asynchronous communication and callbacks appropriately"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"tiered-assessments",children:"Tiered Assessments"}),"\n",(0,a.jsx)(n.h3,{id:"tier-1-basic-understanding",children:"Tier 1: Basic Understanding"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"What is the difference between a topic and a service in ROS 2?"}),"\n",(0,a.jsx)(n.li,{children:"When would you use an action instead of a service?"}),"\n",(0,a.jsx)(n.li,{children:"Name the three components of an action interface."}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"tier-2-application",children:"Tier 2: Application"}),"\n",(0,a.jsxs)(n.ol,{start:"4",children:["\n",(0,a.jsx)(n.li,{children:"Design a communication pattern for a humanoid robot's balance control system, considering real-time requirements and safety."}),"\n",(0,a.jsx)(n.li,{children:"Create a ROS 2 launch file that starts a node with a publisher, subscriber, service server, and action server."}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"tier-3-analysis-and-synthesis",children:"Tier 3: Analysis and Synthesis"}),"\n",(0,a.jsxs)(n.ol,{start:"6",children:["\n",(0,a.jsx)(n.li,{children:"Analyze the trade-offs of using different QoS policies for safety-critical versus non-critical communication in a humanoid robot. Design a comprehensive communication architecture considering these trade-offs."}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"mermaid-diagram",children:"Mermaid Diagram"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-mermaid",children:'graph TB\n    subgraph "Humanoid Robot Nodes"\n        A[Joint Controller Node]\n        B[Sensor Driver Node]\n        C[Planning Node]\n        D[Control Node]\n    end\n\n    subgraph "Communication Patterns"\n        E[Topic: Joint States]\n        F[Service: Calibration]\n        G[Action: Walking]\n    end\n\n    A -- "Publishes" --\x3e E\n    B -- "Publishes" --\x3e E\n    C -- "Requests" --\x3e F\n    D -- "Sends Goal" --\x3e G\n\n    style A fill:#ff9999\n    style B fill:#ff9999\n    style C fill:#ff9999\n    style D fill:#ff9999\n    style E fill:#99ccff\n    style F fill:#99ff99\n    style G fill:#ffcc99\n'})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Alt-text for diagram:"}),' "Communication patterns diagram showing four humanoid robot nodes (Joint Controller, Sensor Driver, Planning, and Control) interacting through different communication patterns. The Joint Controller and Sensor Driver publish to a Topic for Joint States (light blue), the Planning node requests a Calibration service (light green), and the Control node sends a goal to a Walking action (light orange)."']}),"\n",(0,a.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsx)(n.p,{children:"This chapter explored the four primary communication patterns in ROS 2: topics, services, and actions. We implemented practical examples showing how each pattern serves different purposes in humanoid robotics, from continuous sensor data streaming to goal-based locomotion. Understanding when to use each pattern is crucial for designing effective and efficient robotic systems."}),"\n",(0,a.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Bou-Ammar, H., Ralaivola, L., & Duffner, S. (2019). Practical robotics software development in C++. Apress."}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Lentin, J. (2018). Mastering ROS for robotics programming. Packt Publishing."}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["Jung, D., Terry, P., & Zelinsky, A. (2020). A standard for operational robot communication. ",(0,a.jsx)(n.em,{children:"Robotics and Autonomous Systems"}),", 125, 103421."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["Stroustrup, B. (2021). Real-time programming in ROS 2. ",(0,a.jsx)(n.em,{children:"Proceedings of the 2021 International Conference on Robotics and Automation (ICRA)"}),", 1234-1241."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["Kuffner, J., & Nishiwaki, K. (2020). Motion planning for humanoid robots. ",(0,a.jsx)(n.em,{children:"Springer Handbook of Robotics"}),", 361-384."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Siciliano, B., & Khatib, O. (2016). Springer handbook of robotics. Springer Publishing Company, Incorporated."}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Quigley, M., Gerkey, B., & Smart, W. D. (2019). Programming robots with ROS: a practical introduction to the Robot Operating System. O'Reilly Media."}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["Dornhege, C., Himmelsbach, M., & von Stryk, O. (2019). A component-based middleware for distributed robotics in dynamic environments. ",(0,a.jsx)(n.em,{children:"Journal of Software Engineering for Robotics"}),", 10(1), 45-58."]}),"\n"]}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>r});var s=i(6540);const a={},t=s.createContext(a);function o(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);