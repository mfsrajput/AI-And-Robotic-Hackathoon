"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[737],{714:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>m,frontMatter:()=>r,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"vla/llm-task-and-motion-planning","title":"Chapter 2: LLM Task & Motion Planning (Natural Language \u2192 ROS Actions)","description":"Learning Objectives","source":"@site/docs/04-vla/02-llm-task-and-motion-planning.md","sourceDirName":"04-vla","slug":"/vla/llm-task-and-motion-planning","permalink":"/vla/llm-task-and-motion-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/04-vla/02-llm-task-and-motion-planning.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{},"sidebar":"moduleSidebar","previous":{"title":"Chapter 1: Voice-to-Action using OpenAI Whisper (Local Implementation)","permalink":"/vla/voice-to-action-with-whisper"},"next":{"title":"Multi-Modal Integration","permalink":"/vla/multi-modal-integration"}}');var i=t(4848),o=t(8453);const r={},s="Chapter 2: LLM Task & Motion Planning (Natural Language \u2192 ROS Actions)",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"1. Introduction to LLM-Based Task Planning",id:"1-introduction-to-llm-based-task-planning",level:2},{value:"1.1 Why Open-Source LLMs for Robotics?",id:"11-why-open-source-llms-for-robotics",level:3},{value:"1.2 LLM-Robotics Integration Architecture",id:"12-llm-robotics-integration-architecture",level:3},{value:"2. Open-Source LLM Integration",id:"2-open-source-llm-integration",level:2},{value:"2.1 Ollama Integration",id:"21-ollama-integration",level:3},{value:"2.2 Model Selection for Robotics",id:"22-model-selection-for-robotics",level:3},{value:"3. Prompt Engineering for Robotics",id:"3-prompt-engineering-for-robotics",level:2},{value:"3.1 Robotics-Specific Prompting",id:"31-robotics-specific-prompting",level:3},{value:"3.2 Safety-Aware Prompting",id:"32-safety-aware-prompting",level:3},{value:"4. ROS 2 Integration",id:"4-ros-2-integration",level:2},{value:"4.1 ROS 2 Action Server for Task Planning",id:"41-ros-2-action-server-for-task-planning",level:3},{value:"5. Action Sequence Generation",id:"5-action-sequence-generation",level:2},{value:"5.1 Action Sequence Generator Implementation",id:"51-action-sequence-generator-implementation",level:3},{value:"6. Active Learning Exercise: Prompt Engineering Challenge",id:"6-active-learning-exercise-prompt-engineering-challenge",level:2},{value:"6.1 Exercise Overview",id:"61-exercise-overview",level:3},{value:"6.2 Exercise Steps",id:"62-exercise-steps",level:3},{value:"6.3 Implementation Template",id:"63-implementation-template",level:3},{value:"7. Worked Example: Black-Box to Glass-Box Understanding",id:"7-worked-example-black-box-to-glass-box-understanding",level:2},{value:"7.1 Black-Box View",id:"71-black-box-view",level:3},{value:"7.2 Glass-Box View: Complete Implementation",id:"72-glass-box-view-complete-implementation",level:3},{value:"8. Tiered Assessments",id:"8-tiered-assessments",level:2},{value:"Tier 1: Basic Comprehension",id:"tier-1-basic-comprehension",level:3},{value:"Tier 2: Application",id:"tier-2-application",level:3},{value:"Tier 3: Analysis and Synthesis",id:"tier-3-analysis-and-synthesis",level:3},{value:"9. Citations and References",id:"9-citations-and-references",level:2},{value:"10. Summary",id:"10-summary",level:2},{value:"11. Next Steps",id:"11-next-steps",level:2}];function d(n){const e={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.header,{children:(0,i.jsx)(e.h1,{id:"chapter-2-llm-task--motion-planning-natural-language--ros-actions",children:"Chapter 2: LLM Task & Motion Planning (Natural Language \u2192 ROS Actions)"})}),"\n",(0,i.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsx)(e.p,{children:"By the end of this chapter, students will be able to:"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsx)(e.li,{children:"Integrate open-source LLMs (Ollama/Llama-based) for natural language understanding and task planning"}),"\n",(0,i.jsx)(e.li,{children:"Design prompt engineering techniques specifically for robotics task planning"}),"\n",(0,i.jsx)(e.li,{children:"Convert natural language commands to structured ROS action sequences"}),"\n",(0,i.jsx)(e.li,{children:"Implement LLM response parsing and validation for safe robot execution"}),"\n",(0,i.jsx)(e.li,{children:"Create ROS 2 action server interfaces for LLM-based task planning"}),"\n",(0,i.jsx)(e.li,{children:"Apply systematic prompt engineering for reliable robotics task planning"}),"\n",(0,i.jsx)(e.li,{children:"Validate and verify LLM-generated action sequences for safety and correctness"}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"1-introduction-to-llm-based-task-planning",children:"1. Introduction to LLM-Based Task Planning"}),"\n",(0,i.jsx)(e.p,{children:"Large Language Models (LLMs) have revolutionized the field of natural language processing, providing powerful capabilities for understanding and generating human language. In robotics, LLMs can serve as intelligent task planners, converting natural language commands into structured action sequences that robots can execute."}),"\n",(0,i.jsx)(e.p,{children:"This chapter focuses on implementing LLM-based task planning using open-source models like those available through Ollama, with specific emphasis on robotics applications. The system will convert natural language commands to ROS action sequences while maintaining safety and reliability."}),"\n",(0,i.jsx)(e.h3,{id:"11-why-open-source-llms-for-robotics",children:"1.1 Why Open-Source LLMs for Robotics?"}),"\n",(0,i.jsx)(e.p,{children:"The use of open-source LLMs in robotics addresses several critical requirements:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Privacy Compliance"}),": All processing occurs locally with no external data transmission"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Customization"}),": Models can be fine-tuned for specific robotics tasks"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Cost Efficiency"}),": No recurring API costs for educational or research deployment"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Reliability"}),": Systems operate independently of internet connectivity"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Educational Value"}),": Students can examine and modify the entire planning pipeline"]}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"12-llm-robotics-integration-architecture",children:"1.2 LLM-Robotics Integration Architecture"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-mermaid",children:"graph TD\n    A[Natural Language Command] --\x3e B[LLM Service]\n    B --\x3e C[Prompt Engineering]\n    C --\x3e D[Task Planning]\n    D --\x3e E[Action Sequence Generation]\n    E --\x3e F[Validation & Safety Check]\n    F --\x3e G[ROS Action Execution]\n    \n    style A fill:#e1f5fe\n    style G fill:#e8f5e8\n    style B fill:#fff3e0\n    style F fill:#ffebee\n"})}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Figure 2.1"}),": LLM-Robotics Integration Architecture"]}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.em,{children:"Alt-text: Flowchart showing natural language command flowing through LLM service, prompt engineering, task planning, action sequence generation, validation and safety check, to ROS action execution. Natural language input and ROS execution are highlighted in blue and green respectively, with LLM service in orange and validation in light red."})}),"\n",(0,i.jsx)(e.h2,{id:"2-open-source-llm-integration",children:"2. Open-Source LLM Integration"}),"\n",(0,i.jsx)(e.h3,{id:"21-ollama-integration",children:"2.1 Ollama Integration"}),"\n",(0,i.jsx)(e.p,{children:"Ollama provides an easy-to-use interface for running open-source LLMs locally. For robotics applications, we'll focus on models that can understand spatial reasoning, temporal sequences, and action planning."}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# Example Ollama integration for robotics\nimport ollama\n\nclass OllamaRoboticsClient:\n    """\n    Ollama client configured for robotics task planning\n    """\n    \n    def __init__(self, model_name: str = "llama3.1:8b"):\n        self.model_name = model_name\n        self.default_options = {\n            \'temperature\': 0.3,      # Lower temperature for more deterministic output\n            \'num_predict\': 2048,     # Maximum tokens to predict\n            \'top_p\': 0.9,           # Nucleus sampling parameter\n        }\n    \n    def generate_robot_task_plan(self, command: str, context: dict = None) -> dict:\n        """\n        Generate a task plan from natural language command\n        """\n        # Construct system prompt for robotics task planning\n        system_prompt = self._create_robotics_system_prompt(context)\n        \n        # Construct user prompt with command\n        user_prompt = f"Command: {command}"\n        \n        # Generate response\n        response = ollama.chat(\n            model=self.model_name,\n            messages=[\n                {\'role\': \'system\', \'content\': system_prompt},\n                {\'role\': \'user\', \'content\': user_prompt}\n            ],\n            options=self.default_options\n        )\n        \n        return self._parse_response(response[\'message\'][\'content\'])\n    \n    def _create_robotics_system_prompt(self, context: dict = None) -> str:\n        """\n        Create system prompt for robotics task planning\n        """\n        base_prompt = """\n        You are an expert robotics task planner. Convert natural language commands to sequences of ROS actions for humanoid robots.\n        \n        Always output in the following JSON format:\n        {\n            "actions": [\n                {\n                    "action": "action_name",\n                    "parameters": {\n                        "param1": "value1",\n                        "param2": "value2"\n                    }\n                }\n            ],\n            "confidence": 0.8,\n            "reasoning": "Brief explanation of the plan"\n        }\n        \n        Available action types:\n        - navigation: Move robot to a location\n        - manipulation: Manipulate objects\n        - perception: Sense environment\n        - communication: Speak or listen\n        - wait: Pause execution\n        \n        Example:\n        Command: "Go to the kitchen and bring me a red cup"\n        Response: {\n            "actions": [\n                {\n                    "action": "navigation",\n                    "parameters": {\n                        "destination": "kitchen",\n                        "speed": 0.5\n                    }\n                },\n                {\n                    "action": "perception", \n                    "parameters": {\n                        "target": "red cup",\n                        "sensor": "camera"\n                    }\n                },\n                {\n                    "action": "manipulation",\n                    "parameters": {\n                        "action": "grasp",\n                        "object": "red cup"\n                    }\n                }\n            ],\n            "confidence": 0.9,\n            "reasoning": "Navigate to kitchen, identify red cup, grasp it"\n        }\n        """\n        \n        if context:\n            base_prompt += f"\\n\\nAdditional context: {context}"\n        \n        return base_prompt\n    \n    def _parse_response(self, response_text: str) -> dict:\n        """\n        Parse LLM response into structured format\n        """\n        import json\n        import re\n        \n        # Extract JSON from response (in case LLM adds extra text)\n        json_match = re.search(r\'\\{.*\\}\', response_text, re.DOTALL)\n        if json_match:\n            json_str = json_match.group()\n            try:\n                parsed = json.loads(json_str)\n                return parsed\n            except json.JSONDecodeError:\n                return {\n                    "actions": [],\n                    "confidence": 0.0,\n                    "reasoning": "Failed to parse LLM response",\n                    "raw_response": response_text\n                }\n        else:\n            return {\n                "actions": [],\n                "confidence": 0.0,\n                "reasoning": "No valid JSON found in LLM response",\n                "raw_response": response_text\n            }\n\n# Example usage\nif __name__ == "__main__":\n    client = OllamaRoboticsClient("llama3.1:8b")\n    \n    # Test command\n    command = "Go to the kitchen and bring me the red cup"\n    result = client.generate_robot_task_plan(command)\n    \n    print(f"Command: {command}")\n    print(f"Generated plan: {result}")\n'})}),"\n",(0,i.jsx)(e.h3,{id:"22-model-selection-for-robotics",children:"2.2 Model Selection for Robotics"}),"\n",(0,i.jsx)(e.p,{children:"Different LLMs have varying capabilities for robotics task planning:"}),"\n",(0,i.jsxs)(e.table,{children:[(0,i.jsx)(e.thead,{children:(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.th,{children:"Model"}),(0,i.jsx)(e.th,{children:"Size"}),(0,i.jsx)(e.th,{children:"Robotics Capabilities"}),(0,i.jsx)(e.th,{children:"Memory Usage"}),(0,i.jsx)(e.th,{children:"Performance"})]})}),(0,i.jsxs)(e.tbody,{children:[(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"llama3.1:8b"}),(0,i.jsx)(e.td,{children:"8B"}),(0,i.jsx)(e.td,{children:"Good spatial reasoning"}),(0,i.jsx)(e.td,{children:"8GB"}),(0,i.jsx)(e.td,{children:"Fast"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"llama3.1:70b"}),(0,i.jsx)(e.td,{children:"70B"}),(0,i.jsx)(e.td,{children:"Excellent reasoning"}),(0,i.jsx)(e.td,{children:"16GB+"}),(0,i.jsx)(e.td,{children:"Slow"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"mistral:7b"}),(0,i.jsx)(e.td,{children:"7B"}),(0,i.jsx)(e.td,{children:"Moderate capabilities"}),(0,i.jsx)(e.td,{children:"6GB"}),(0,i.jsx)(e.td,{children:"Fast"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"phi3:3.8b"}),(0,i.jsx)(e.td,{children:"3.8B"}),(0,i.jsx)(e.td,{children:"Basic reasoning"}),(0,i.jsx)(e.td,{children:"4GB"}),(0,i.jsx)(e.td,{children:"Very Fast"})]})]})]}),"\n",(0,i.jsxs)(e.p,{children:["For educational robotics, the ",(0,i.jsx)(e.code,{children:"llama3.1:8b"})," model provides an optimal balance of capabilities and resource requirements."]}),"\n",(0,i.jsx)(e.h2,{id:"3-prompt-engineering-for-robotics",children:"3. Prompt Engineering for Robotics"}),"\n",(0,i.jsx)(e.h3,{id:"31-robotics-specific-prompting",children:"3.1 Robotics-Specific Prompting"}),"\n",(0,i.jsx)(e.p,{children:"Effective prompt engineering for robotics requires specialized techniques that account for the physical world, safety constraints, and action sequences."}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'class RoboticsPromptEngineer:\n    """\n    Specialized prompt engineering for robotics applications\n    """\n    \n    def __init__(self):\n        self.base_system_prompt = self._get_base_system_prompt()\n        self.safety_constraints = self._get_safety_constraints()\n        self.action_templates = self._get_action_templates()\n    \n    def _get_base_system_prompt(self) -> str:\n        """\n        Base system prompt for robotics task planning\n        """\n        return """\n        You are an expert robotics task planner. Your role is to convert natural language commands into safe, executable action sequences for humanoid robots.\n        \n        ## Core Principles:\n        1. Prioritize safety in all action sequences\n        2. Break complex tasks into simple, verifiable steps\n        3. Include perception steps to verify environment conditions\n        4. Account for robot capabilities and limitations\n        5. Plan for error recovery and contingencies\n        \n        ## Output Format:\n        Always respond with valid JSON containing:\n        - actions: Array of action objects\n        - confidence: Confidence score (0.0-1.0)\n        - reasoning: Brief explanation of the plan\n        - safety_check: Whether safety was verified\n        \n        ## Action Schema:\n        {\n            "action": "action_type",\n            "parameters": {\n                "param1": "value1"\n            },\n            "verification": "how to verify completion"\n        }\n        """\n    \n    def _get_safety_constraints(self) -> dict:\n        """\n        Safety constraints for robotics task planning\n        """\n        return {\n            "no_harm": "Actions must not cause harm to humans or environment",\n            "navigation_safety": "Verify path is clear before navigation",\n            "manipulation_limits": "Respect robot\'s weight and size limitations",\n            "communication_bounds": "Limit communication to appropriate contexts",\n            "error_handling": "Include error recovery steps"\n        }\n    \n    def _get_action_templates(self) -> dict:\n        """\n        Template for different action types\n        """\n        return {\n            "navigation": {\n                "required_params": ["destination"],\n                "optional_params": ["speed", "avoid_obstacles", "precision"],\n                "verification": "Check robot\'s position vs destination"\n            },\n            "manipulation": {\n                "required_params": ["action", "object"],\n                "optional_params": ["position", "force", "gripper_width"],\n                "verification": "Check object state and gripper status"\n            },\n            "perception": {\n                "required_params": ["target"],\n                "optional_params": ["sensor", "accuracy", "timeout"],\n                "verification": "Validate perception results"\n            },\n            "communication": {\n                "required_params": ["message"],\n                "optional_params": ["recipient", "volume", "language"],\n                "verification": "Confirm message was processed"\n            }\n        }\n    \n    def create_task_planning_prompt(self, command: str, environment_context: dict = None) -> tuple:\n        """\n        Create a complete prompt for task planning\n        """\n        system_prompt = self.base_system_prompt\n        \n        # Add environment context if available\n        if environment_context:\n            env_context = f"\\n\\n## Environment Context:\\n{environment_context}"\n            system_prompt += env_context\n        \n        # Add command-specific instructions\n        user_prompt = f"""\n        ## Task Command:\n        {command}\n        \n        ## Requirements:\n        1. Generate a sequence of 2-8 actions maximum\n        2. Include perception steps where appropriate\n        3. Verify safety constraints are met\n        4. Include error handling where needed\n        5. Output in the specified JSON format\n        \n        ## Example Output Format:\n        {{\n            "actions": [\n                {{\n                    "action": "navigation",\n                    "parameters": {{\n                        "destination": "kitchen"\n                    }},\n                    "verification": "Robot reached kitchen area"\n                }}\n            ],\n            "confidence": 0.85,\n            "reasoning": "Navigate to kitchen to begin task",\n            "safety_check": true\n        }}\n        """\n        \n        return system_prompt, user_prompt\n    \n    def validate_generated_plan(self, plan: dict) -> dict:\n        """\n        Validate a generated plan for safety and feasibility\n        """\n        validation_results = {\n            "is_valid": True,\n            "issues": [],\n            "suggestions": [],\n            "confidence": plan.get("confidence", 0.0)\n        }\n        \n        # Check if actions exist\n        if "actions" not in plan:\n            validation_results["is_valid"] = False\n            validation_results["issues"].append("No actions found in plan")\n            return validation_results\n        \n        actions = plan["actions"]\n        \n        # Validate each action\n        for i, action in enumerate(actions):\n            if "action" not in action:\n                validation_results["is_valid"] = False\n                validation_results["issues"].append(f"Action {i} missing action type")\n                continue\n            \n            action_type = action["action"]\n            if action_type not in self.action_templates:\n                validation_results["suggestions"].append(\n                    f"Action {i} uses unknown type \'{action_type}\'. Available types: {list(self.action_templates.keys())}"\n                )\n        \n        return validation_results\n\n# Example usage for educational purposes\nengineer = RoboticsPromptEngineer()\nsystem_prompt, user_prompt = engineer.create_task_planning_prompt("Go to the kitchen and bring me the red cup")\nprint(f"System prompt length: {len(system_prompt)}")\nprint(f"User prompt length: {len(user_prompt)}")\n'})}),"\n",(0,i.jsx)(e.h3,{id:"32-safety-aware-prompting",children:"3.2 Safety-Aware Prompting"}),"\n",(0,i.jsx)(e.p,{children:"Safety is paramount in robotics applications, requiring specialized prompt engineering:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'class SafetyAwarePrompter:\n    """\n    Prompt engineering with safety considerations\n    """\n    \n    def __init__(self):\n        self.safety_principles = [\n            "Never plan actions that could harm humans",\n            "Always verify environment before navigation",\n            "Include error recovery in all plans",\n            "Respect robot\'s physical limitations",\n            "Plan for unexpected obstacles"\n        ]\n    \n    def create_safe_task_prompt(self, command: str) -> tuple:\n        """\n        Create a prompt that emphasizes safety\n        """\n        system_prompt = f"""\n        # SAFETY-CRITICAL ROBOTICS TASK PLANNER\n        You are controlling a safety-critical humanoid robot. All actions must prioritize human safety above task completion.\n        \n        ## SAFETY PRINCIPLES:\n        {chr(10).join(f"- {principle}" for principle in self.safety_principles)}\n        \n        ## SAFETY REQUIREMENTS FOR EVERY PLAN:\n        1. Include perception step before navigation\n        2. Verify destination is safe and accessible\n        3. Check for obstacles in path\n        4. Plan escape route if needed\n        5. Include safety verification after each major action\n        \n        ## OUTPUT FORMAT:\n        {{\n            "actions": [...],\n            "safety_checks": [...],\n            "risk_assessment": "low/medium/high",\n            "confidence": 0.0-1.0,\n            "reasoning": "Safety considerations included"\n        }}\n        """\n        \n        user_prompt = f"""\n        ## TASK COMMAND:\n        {command}\n        \n        ## SAFETY-CRITICAL REQUIREMENTS:\n        - Generate maximum 5 actions to minimize risk exposure\n        - Include safety check after each action\n        - Plan for human presence in environment\n        - Verify robot capabilities match task requirements\n        - Output only in specified JSON format\n        \n        ## EXAMPLE SAFE PLAN:\n        {{\n            "actions": [\n                {{\n                    "action": "perception",\n                    "parameters": {{"target": "path_to_destination", "sensor": "lidar"}},\n                    "safety_check": "Verify path is clear"\n                }},\n                {{\n                    "action": "navigation", \n                    "parameters": {{"destination": "kitchen", "speed": 0.3}},\n                    "safety_check": "Navigate slowly with obstacle detection"\n                }}\n            ],\n            "safety_checks": ["path_clear", "speed_controlled", "obstacle_detection_active"],\n            "risk_assessment": "low",\n            "confidence": 0.9,\n            "reasoning": "Slow navigation with continuous safety monitoring"\n        }}\n        """\n        \n        return system_prompt, user_prompt\n'})}),"\n",(0,i.jsx)(e.h2,{id:"4-ros-2-integration",children:"4. ROS 2 Integration"}),"\n",(0,i.jsx)(e.h3,{id:"41-ros-2-action-server-for-task-planning",children:"4.1 ROS 2 Action Server for Task Planning"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import rclpy\nfrom rclpy.action import ActionServer, GoalResponse, CancelResponse\nfrom rclpy.node import Node\nfrom rclpy.callback_groups import ReentrantCallbackGroup\nfrom rclpy.executors import MultiThreadedExecutor\n\nfrom std_msgs.msg import String\nfrom geometry_msgs.msg import Pose\nfrom action_msgs.msg import GoalStatus\nimport json\nimport threading\nimport time\n\nfrom common_data_models import Command, ActionSequence\nfrom observability_utils import EducationalLogger, MetricsCollector, DebuggingHelper\nfrom error_handling_utils import EducationalErrorHandler, InputValidator\n\n\nclass LLMTaskPlanningActionServer(Node):\n    """\n    ROS 2 Action Server for LLM-based task planning\n    Converts natural language commands to ROS action sequences\n    """\n    \n    def __init__(self):\n        super().__init__(\'llm_task_planning_action_server\')\n        \n        # Initialize educational utilities\n        self.logger = EducationalLogger("llm_task_planning")\n        self.metrics = MetricsCollector(self.logger)\n        self.debug_helper = DebuggingHelper(self.logger)\n        self.error_handler = EducationalErrorHandler()\n        self.validator = InputValidator(self.error_handler)\n        \n        # Initialize LLM client\n        self.llm_client = self._initialize_llm_client()\n        \n        # Initialize prompt engineer\n        self.prompt_engineer = RoboticsPromptEngineer()\n        \n        # Create action server\n        self._action_server = ActionServer(\n            self,\n            # Using a generic action interface since we\'re not creating the full ROS 2 action definition here\n            self.execute_callback,\n            \'llm_task_plan\',\n            goal_callback=self.goal_callback,\n            cancel_callback=self.cancel_callback,\n            callback_group=ReentrantCallbackGroup()\n        )\n        \n        # Create publishers for intermediate results\n        self.plan_publisher = self.create_publisher(\n            String,\n            \'llm_task_plans\',\n            10\n        )\n        \n        self.feedback_publisher = self.create_publisher(\n            String,\n            \'llm_task_feedback\',\n            10\n        )\n        \n        self.logger.info("LLMTaskPlanningActionServer", "__init__", "LLM task planning action server initialized")\n    \n    def _initialize_llm_client(self):\n        """\n        Initialize LLM client for task planning\n        In practice, this would connect to Ollama or local LLM\n        """\n        # For this educational example, we\'ll create a mock client\n        # In a real implementation, this would connect to Ollama\n        class MockLLMClient:\n            def generate_robot_task_plan(self, command: str, context: dict = None):\n                # Simulate LLM processing\n                time.sleep(0.5)  # Simulate processing time\n                \n                # Generate mock response based on command\n                if "kitchen" in command.lower():\n                    actions = [\n                        {\n                            "action": "navigation",\n                            "parameters": {"destination": "kitchen", "speed": 0.5}\n                        },\n                        {\n                            "action": "perception",\n                            "parameters": {"target": "environment", "sensor": "camera"}\n                        }\n                    ]\n                elif "bring" in command.lower() or "get" in command.lower():\n                    actions = [\n                        {\n                            "action": "navigation", \n                            "parameters": {"destination": "object_location", "speed": 0.5}\n                        },\n                        {\n                            "action": "manipulation",\n                            "parameters": {"action": "grasp", "object": "target_object"}\n                        },\n                        {\n                            "action": "navigation",\n                            "parameters": {"destination": "return_location", "speed": 0.5}\n                        }\n                    ]\n                else:\n                    actions = [\n                        {\n                            "action": "communication",\n                            "parameters": {"message": f"Processing command: {command}"}\n                        }\n                    ]\n                \n                return {\n                    "actions": actions,\n                    "confidence": 0.85,\n                    "reasoning": "Generated plan based on command keywords",\n                    "safety_check": True\n                }\n        \n        return MockLLMClient()\n    \n    def goal_callback(self, goal_request):\n        """Handle incoming task planning goals"""\n        try:\n            self.logger.info("LLMTaskPlanningActionServer", "goal_callback", "Received task planning goal", {\n                \'command\': goal_request.command_text\n            })\n            \n            # Validate goal\n            if not goal_request.command_text.strip():\n                self.logger.warning("LLMTaskPlanningActionServer", "goal_callback", "Empty command received")\n                return GoalResponse.REJECT\n            \n            # Validate command length\n            if len(goal_request.command_text) > 500:  # Arbitrary limit\n                self.logger.warning("LLMTaskPlanningActionServer", "goal_callback", "Command too long")\n                return GoalResponse.REJECT\n            \n            self.logger.info("LLMTaskPlanningActionServer", "goal_callback", "Accepting goal request")\n            return GoalResponse.ACCEPT\n            \n        except Exception as e:\n            self.error_handler.handle_error(\n                e,\n                context="goal_callback",\n                suggested_fix="Check goal request validation",\n                learning_objective="Handle goal validation errors"\n            )\n            return GoalResponse.REJECT\n    \n    def cancel_callback(self, goal_handle):\n        """Handle goal cancellation requests"""\n        self.logger.info("LLMTaskPlanningActionServer", "cancel_callback", "Received cancel request")\n        return CancelResponse.ACCEPT\n    \n    async def execute_callback(self, goal_handle):\n        """Execute the task planning goal"""\n        self.logger.info("LLMTaskPlanningActionServer", "execute_callback", "Executing task planning goal")\n        \n        try:\n            goal = goal_request\n            feedback_msg = type(\'TaskPlanningFeedback\', (), {})()  # Placeholder feedback\n            result = type(\'TaskPlanningResult\', (), {})()  # Placeholder result\n            \n            # Process the command through LLM\n            feedback_msg.status = \'Processing natural language command\'\n            goal_handle.publish_feedback(feedback_msg)\n            \n            # Generate task plan using LLM\n            llm_result = self.llm_client.generate_robot_task_plan(goal.command_text)\n            \n            # Validate the generated plan\n            validation_result = self.prompt_engineer.validate_generated_plan(llm_result)\n            \n            if not validation_result[\'is_valid\']:\n                self.logger.error("LLMTaskPlanningActionServer", "execute_callback", \n                                "Generated plan failed validation", {\n                                    \'issues\': validation_result[\'issues\']\n                                })\n                \n                result.success = False\n                result.message = f"Plan validation failed: {validation_result[\'issues\']}"\n                result.action_sequence = []\n                result.confidence = 0.0\n                \n                goal_handle.abort()\n                return result\n            \n            # Convert to action sequence\n            action_sequence = self._convert_to_action_sequence(llm_result, goal.command_text)\n            \n            # Publish the plan\n            plan_msg = String()\n            plan_msg.data = json.dumps(action_sequence.to_dict())\n            self.plan_publisher.publish(plan_msg)\n            \n            feedback_msg.status = \'Plan generated and validated\'\n            goal_handle.publish_feedback(feedback_msg)\n            \n            # Set result\n            result.success = True\n            result.message = "Task plan generated successfully"\n            result.action_sequence = action_sequence.commands  # Simplified for example\n            result.confidence = llm_result.get(\'confidence\', 0.0)\n            result.reasoning = llm_result.get(\'reasoning\', \'\')\n            \n            goal_handle.succeed()\n            self.logger.info("LLMTaskPlanningActionServer", "execute_callback", "Goal completed successfully", {\n                \'action_count\': len(action_sequence.commands),\n                \'confidence\': result.confidence\n            })\n            \n            return result\n            \n        except Exception as e:\n            self.error_handler.handle_error(\n                e,\n                context="execute_callback",\n                suggested_fix="Check task planning execution logic",\n                learning_objective="Handle task planning execution errors"\n            )\n            \n            result = type(\'TaskPlanningResult\', (), {})()\n            result.success = False\n            result.message = f"Execution error: {str(e)}"\n            result.action_sequence = []\n            result.confidence = 0.0\n            \n            goal_handle.abort()\n            return result\n    \n    def _convert_to_action_sequence(self, llm_result: dict, original_command: str) -> ActionSequence:\n        """\n        Convert LLM result to ActionSequence data model\n        """\n        commands = llm_result.get(\'actions\', [])\n        confidence = llm_result.get(\'confidence\', 0.0)\n        \n        action_sequence = ActionSequence(\n            commands=commands,\n            context={\n                \'original_command\': original_command,\n                \'llm_reasoning\': llm_result.get(\'reasoning\', \'\'),\n                \'safety_verified\': llm_result.get(\'safety_check\', False)\n            },\n            status=\'pending\',\n            created_at=__import__(\'datetime\').datetime.now()\n        )\n        \n        return action_sequence\n\n\nclass LLMIntegrationService:\n    """\n    Service class for LLM integration in the VLA system\n    """\n    \n    def __init__(self, model_name: str = "llama3.1:8b"):\n        self.model_name = model_name\n        self.logger = EducationalLogger("llm_integration_service")\n        self.metrics = MetricsCollector(self.logger)\n        self.debug_helper = DebuggingHelper(self.logger)\n        self.error_handler = EducationalErrorHandler()\n        self.validator = InputValidator(self.error_handler)\n        \n        # Initialize prompt engineer\n        self.prompt_engineer = RoboticsPromptEngineer()\n        \n        # Initialize mock LLM client (in real implementation, this would connect to Ollama)\n        self.llm_client = self._initialize_llm_client()\n        \n        # Processing statistics\n        self.total_processed = 0\n        self.total_errors = 0\n        \n        self.logger.info("LLMIntegrationService", "__init__", "LLM integration service initialized", {\n            \'model_name\': self.model_name\n        })\n    \n    def _initialize_llm_client(self):\n        """\n        Initialize LLM client for the service\n        """\n        # Mock implementation for educational purposes\n        class MockLLMClient:\n            def generate_response(self, prompt: str, system_prompt: str = ""):\n                # Simulate LLM processing\n                import time\n                time.sleep(0.3)  # Simulate processing time\n                \n                # Mock response based on prompt content\n                if "navigate" in prompt.lower() or "go to" in prompt.lower():\n                    return {\n                        "actions": [\n                            {\n                                "action": "navigation",\n                                "parameters": {"destination": "location", "speed": 0.5}\n                            }\n                        ],\n                        "confidence": 0.8,\n                        "reasoning": "Navigation command detected"\n                    }\n                elif "grasp" in prompt.lower() or "pick" in prompt.lower():\n                    return {\n                        "actions": [\n                            {\n                                "action": "manipulation",\n                                "parameters": {"action": "grasp", "object": "item"}\n                            }\n                        ],\n                        "confidence": 0.75,\n                        "reasoning": "Manipulation command detected"\n                    }\n                else:\n                    return {\n                        "actions": [\n                            {\n                                "action": "communication",\n                                "parameters": {"message": "Processing command"}\n                            }\n                        ],\n                        "confidence": 0.6,\n                        "reasoning": "General command detected"\n                    }\n        \n        return MockLLMClient()\n    \n    def process_natural_language_command(self, command: str, context: dict = None) -> ActionSequence:\n        """\n        Process a natural language command and return an action sequence\n        """\n        start_time = self.metrics.start_timer(\'llm_processing\')\n        \n        try:\n            self.logger.debug("LLMIntegrationService", "process_natural_language_command", \n                            "Processing command", {\n                                \'command\': command,\n                                \'context_keys\': list(context.keys()) if context else []\n                            })\n            \n            # Validate input\n            if not self.validator.validate_not_empty(command, "command"):\n                raise ValueError("Command cannot be empty")\n            \n            if len(command) > 1000:  # Arbitrary limit\n                raise ValueError("Command too long (max 1000 characters)")\n            \n            # Create prompt for the LLM\n            system_prompt, user_prompt = self.prompt_engineer.create_task_planning_prompt(\n                command, context\n            )\n            \n            # Get response from LLM\n            llm_response = self.llm_client.generate_response(user_prompt, system_prompt)\n            \n            # Validate the response\n            validation_result = self.prompt_engineer.validate_generated_plan(llm_response)\n            \n            if not validation_result[\'is_valid\']:\n                self.logger.error("LLMIntegrationService", "process_natural_language_command", \n                                "LLM response failed validation", {\n                                    \'issues\': validation_result[\'issues\']\n                                })\n                # Return a safe fallback plan\n                llm_response = {\n                    "actions": [{\n                        "action": "communication",\n                        "parameters": {"message": f"Unable to process command: {command}"}\n                    }],\n                    "confidence": 0.0,\n                    "reasoning": "Validation failed, using fallback"\n                }\n            \n            # Convert to ActionSequence\n            action_sequence = self._convert_to_action_sequence(llm_response, command, context)\n            \n            # Record metrics\n            processing_time = self.metrics.stop_timer(\'llm_processing\')\n            self.metrics.record_metric(\'llm_processing_time\', processing_time)\n            self.metrics.record_metric(\'commands_processed\', 1)\n            \n            self.total_processed += 1\n            \n            self.logger.info("LLMIntegrationService", "process_natural_language_command", \n                           "Command processed successfully", {\n                               \'action_count\': len(action_sequence.commands),\n                               \'confidence\': action_sequence.context.get(\'confidence\', 0),\n                               \'processing_time\': processing_time\n                           })\n            \n            return action_sequence\n            \n        except Exception as e:\n            self.total_errors += 1\n            processing_time = self.metrics.stop_timer(\'llm_processing\')\n            self.metrics.record_metric(\'llm_processing_error_time\', processing_time)\n            \n            self.error_handler.handle_error(\n                e,\n                context="process_natural_language_command",\n                suggested_fix="Check command format and LLM connectivity",\n                learning_objective="Handle LLM processing errors"\n            )\n            \n            # Return a safe fallback action sequence\n            return ActionSequence(\n                commands=[{\n                    "action": "communication",\n                    "parameters": {"message": f"Error processing command: {str(e)}"}\n                }],\n                context={"error": str(e)},\n                status="failed",\n                created_at=__import__(\'datetime\').datetime.now()\n            )\n    \n    def _convert_to_action_sequence(self, llm_response: dict, command: str, context: dict = None) -> ActionSequence:\n        """\n        Convert LLM response to ActionSequence data model\n        """\n        commands = llm_response.get(\'actions\', [])\n        confidence = llm_response.get(\'confidence\', 0.0)\n        \n        sequence_context = {\n            \'original_command\': command,\n            \'llm_reasoning\': llm_response.get(\'reasoning\', \'\'),\n            \'confidence\': confidence,\n            \'safety_verified\': llm_response.get(\'safety_check\', False)\n        }\n        \n        if context:\n            sequence_context.update(context)\n        \n        action_sequence = ActionSequence(\n            commands=commands,\n            context=sequence_context,\n            status=\'pending\',\n            created_at=__import__(\'datetime\').datetime.now()\n        )\n        \n        return action_sequence\n    \n    def get_service_status(self) -> dict:\n        """\n        Get current status of the LLM service\n        """\n        return {\n            \'model_name\': self.model_name,\n            \'total_processed\': self.total_processed,\n            \'total_errors\': self.total_errors,\n            \'error_rate\': self.total_errors / max(1, self.total_processed),\n            \'metrics\': self.metrics.get_statistics(),\n            \'prompt_engineer_status\': {\n                \'safety_constraints_count\': len(self.prompt_engineer.safety_constraints),\n                \'action_templates_count\': len(self.prompt_engineer.action_templates)\n            }\n        }\n\n\ndef main(args=None):\n    """\n    Main function to run the LLM task planning node\n    """\n    rclpy.init(args=args)\n    \n    # Create the LLM task planning server\n    llm_server = LLMTaskPlanningActionServer()\n    \n    # Use MultiThreadedExecutor to handle callbacks in separate threads\n    executor = MultiThreadedExecutor()\n    executor.add_node(llm_server)\n    \n    try:\n        llm_server.logger.info("LLMTaskPlanningActionServer", "main", "Starting LLM task planning server")\n        executor.spin()\n    except KeyboardInterrupt:\n        llm_server.logger.info("LLMTaskPlanningActionServer", "main", "Interrupted by user")\n    except Exception as e:\n        llm_server.error_handler.handle_error(\n            e,\n            context="main",\n            suggested_fix="Check node initialization and execution",\n            learning_objective="Handle ROS 2 node lifecycle errors"\n        )\n    finally:\n        llm_server.logger.info("LLMTaskPlanningActionServer", "main", "Shutting down LLM task planning server")\n        llm_server.destroy_node()\n        rclpy.shutdown()\n\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,i.jsx)(e.h2,{id:"5-action-sequence-generation",children:"5. Action Sequence Generation"}),"\n",(0,i.jsx)(e.h3,{id:"51-action-sequence-generator-implementation",children:"5.1 Action Sequence Generator Implementation"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"from typing import List, Dict, Any, Optional\nfrom datetime import datetime\nimport re\nimport json\n\n\nclass ActionSequenceGenerator:\n    \"\"\"\n    Generates structured action sequences from LLM responses\n    \"\"\"\n    \n    def __init__(self):\n        self.logger = EducationalLogger(\"action_sequence_generator\")\n        self.metrics = MetricsCollector(self.logger)\n        self.error_handler = EducationalErrorHandler()\n        self.validator = InputValidator(self.error_handler)\n        \n        # Define valid action types and their parameters\n        self.valid_actions = {\n            'navigation': {\n                'required': ['destination'],\n                'optional': ['speed', 'avoid_obstacles', 'precision', 'max_speed']\n            },\n            'manipulation': {\n                'required': ['action', 'object'],\n                'optional': ['position', 'force', 'gripper_width', 'approach_angle']\n            },\n            'perception': {\n                'required': ['target'],\n                'optional': ['sensor', 'accuracy', 'timeout', 'roi']\n            },\n            'communication': {\n                'required': ['message'],\n                'optional': ['recipient', 'volume', 'language', 'emotion']\n            },\n            'wait': {\n                'required': ['duration'],\n                'optional': ['condition', 'timeout']\n            },\n            'conditional': {\n                'required': ['condition', 'action_if_true'],\n                'optional': ['action_if_false', 'timeout']\n            }\n        }\n    \n    def generate_action_sequence(self, llm_response: dict, original_command: str) -> ActionSequence:\n        \"\"\"\n        Generate a validated action sequence from LLM response\n        \"\"\"\n        try:\n            self.logger.debug(\"ActionSequenceGenerator\", \"generate_action_sequence\", \n                            \"Generating action sequence\", {\n                                'command': original_command,\n                                'response_keys': list(llm_response.keys())\n                            })\n            \n            # Extract actions from response\n            raw_actions = llm_response.get('actions', [])\n            \n            # Validate and clean actions\n            validated_actions = []\n            for i, action in enumerate(raw_actions):\n                validated_action = self._validate_action(action, i)\n                if validated_action:\n                    validated_actions.append(validated_action)\n            \n            # Create context with original information\n            context = {\n                'original_command': original_command,\n                'llm_confidence': llm_response.get('confidence', 0.0),\n                'llm_reasoning': llm_response.get('reasoning', ''),\n                'generated_at': datetime.now().isoformat(),\n                'action_count': len(validated_actions)\n            }\n            \n            # Create ActionSequence\n            action_sequence = ActionSequence(\n                commands=validated_actions,\n                context=context,\n                status='generated',\n                created_at=datetime.now()\n            )\n            \n            # Update metrics\n            self.metrics.record_metric('action_sequences_generated', 1)\n            self.metrics.record_metric('average_action_count', len(validated_actions))\n            \n            self.logger.info(\"ActionSequenceGenerator\", \"generate_action_sequence\", \n                           \"Action sequence generated\", {\n                               'action_count': len(validated_actions),\n                               'confidence': llm_response.get('confidence', 0.0)\n                           })\n            \n            return action_sequence\n            \n        except Exception as e:\n            self.error_handler.handle_error(\n                e,\n                context=\"generate_action_sequence\",\n                suggested_fix=\"Check LLM response format and validation logic\",\n                learning_objective=\"Handle action sequence generation errors\"\n            )\n            # Return empty sequence on error\n            return ActionSequence(\n                commands=[],\n                context={'error': str(e)},\n                status='failed',\n                created_at=datetime.now()\n            )\n    \n    def _validate_action(self, action: dict, index: int) -> Optional[dict]:\n        \"\"\"\n        Validate a single action against the action schema\n        \"\"\"\n        try:\n            # Check if action has required fields\n            if not isinstance(action, dict):\n                self.logger.warning(\"ActionSequenceGenerator\", \"_validate_action\", \n                                  f\"Action {index} is not a dictionary: {type(action)}\")\n                return None\n            \n            if 'action' not in action:\n                self.logger.warning(\"ActionSequenceGenerator\", \"_validate_action\", \n                                  f\"Action {index} missing 'action' field: {action}\")\n                return None\n            \n            action_type = action['action']\n            \n            # Check if action type is valid\n            if action_type not in self.valid_actions:\n                self.logger.warning(\"ActionSequenceGenerator\", \"_validate_action\", \n                                  f\"Unknown action type at {index}: {action_type}\")\n                return None\n            \n            # Get action schema\n            schema = self.valid_actions[action_type]\n            \n            # Check required parameters\n            params = action.get('parameters', {})\n            missing_required = []\n            \n            for required_param in schema['required']:\n                if required_param not in params:\n                    missing_required.append(required_param)\n            \n            if missing_required:\n                self.logger.warning(\"ActionSequenceGenerator\", \"_validate_action\", \n                                  f\"Action {index} missing required parameters: {missing_required}\")\n                # Add defaults where possible, otherwise return None\n                if action_type == 'navigation' and 'destination' in missing_required:\n                    # This is critical, cannot proceed without destination\n                    return None\n                elif action_type == 'manipulation' and 'object' in missing_required:\n                    # This is critical, cannot proceed without object\n                    return None\n                else:\n                    # For other missing parameters, add defaults\n                    for param in missing_required:\n                        if param == 'speed':\n                            params[param] = 0.5\n                        elif param == 'duration':\n                            params[param] = 1.0\n                        else:\n                            params[param] = None\n            \n            # Validate parameter types and values\n            validated_params = self._validate_parameters(params, action_type)\n            \n            # Return validated action\n            validated_action = {\n                'action': action_type,\n                'parameters': validated_params,\n                'verification': action.get('verification', f'Complete {action_type} action'),\n                'timeout': action.get('timeout', 30.0)  # Default 30 second timeout\n            }\n            \n            return validated_action\n            \n        except Exception as e:\n            self.error_handler.handle_error(\n                e,\n                context=f\"validate_action_{index}\",\n                suggested_fix=\"Check action validation logic\",\n                learning_objective=\"Handle action validation errors\"\n            )\n            return None\n    \n    def _validate_parameters(self, params: dict, action_type: str) -> dict:\n        \"\"\"\n        Validate action parameters based on action type\n        \"\"\"\n        validated_params = {}\n        \n        for param_name, param_value in params.items():\n            # Validate based on parameter name and action type\n            if param_name == 'speed':\n                # Validate speed is between 0 and 1\n                try:\n                    speed = float(param_value)\n                    validated_params[param_name] = max(0.0, min(1.0, speed))\n                except (ValueError, TypeError):\n                    validated_params[param_name] = 0.5  # Default speed\n            elif param_name == 'duration':\n                # Validate duration is positive\n                try:\n                    duration = float(param_value)\n                    validated_params[param_name] = max(0.0, duration)\n                except (ValueError, TypeError):\n                    validated_params[param_name] = 1.0  # Default duration\n            elif param_name == 'destination':\n                # Validate destination is a string\n                validated_params[param_name] = str(param_value) if param_value is not None else \"unknown\"\n            elif param_name == 'object':\n                # Validate object is a string\n                validated_params[param_name] = str(param_value) if param_value is not None else \"unknown\"\n            elif param_name == 'force':\n                # Validate force is between 0 and 100\n                try:\n                    force = float(param_value)\n                    validated_params[param_name] = max(0.0, min(100.0, force))\n                except (ValueError, TypeError):\n                    validated_params[param_name] = 50.0  # Default force\n            else:\n                # For other parameters, keep as is\n                validated_params[param_name] = param_value\n        \n        return validated_params\n\n\n# Example usage\nif __name__ == \"__main__\":\n    generator = ActionSequenceGenerator()\n    \n    # Example LLM response\n    llm_response = {\n        'actions': [\n            {\n                'action': 'navigation',\n                'parameters': {\n                    'destination': 'kitchen',\n                    'speed': 0.5\n                }\n            },\n            {\n                'action': 'perception',\n                'parameters': {\n                    'target': 'red cup',\n                    'sensor': 'camera'\n                }\n            },\n            {\n                'action': 'manipulation', \n                'parameters': {\n                    'action': 'grasp',\n                    'object': 'red cup',\n                    'force': 60.0\n                }\n            }\n        ],\n        'confidence': 0.85,\n        'reasoning': 'Navigate to kitchen, identify red cup, grasp it'\n    }\n    \n    command = \"Go to the kitchen and bring me the red cup\"\n    sequence = generator.generate_action_sequence(llm_response, command)\n    \n    print(f\"Generated sequence with {len(sequence.commands)} actions\")\n    print(f\"Context: {sequence.context}\")\n"})}),"\n",(0,i.jsx)(e.h2,{id:"6-active-learning-exercise-prompt-engineering-challenge",children:"6. Active Learning Exercise: Prompt Engineering Challenge"}),"\n",(0,i.jsx)(e.h3,{id:"61-exercise-overview",children:"6.1 Exercise Overview"}),"\n",(0,i.jsx)(e.p,{children:"Students will design effective prompts for robotics task planning, considering safety, clarity, and reliability."}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Learning Objective"}),": Understand how prompt engineering affects LLM performance in robotics applications."]}),"\n",(0,i.jsx)(e.h3,{id:"62-exercise-steps",children:"6.2 Exercise Steps"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Prompt Analysis"}),": Analyze existing prompts for strengths and weaknesses"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Safety Integration"}),": Add safety considerations to prompts"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Testing"}),": Test prompts with various commands"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Iteration"}),": Refine prompts based on results"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Validation"}),": Validate safety and reliability of generated plans"]}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"63-implementation-template",children:"6.3 Implementation Template"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'class PromptEngineeringExercise:\n    """\n    Educational template for prompt engineering in robotics\n    """\n    \n    def __init__(self):\n        self.base_prompts = {\n            \'simple\': "Convert this command to robot actions: {command}",\n            \'structured\': """\n            Convert the command to structured robot actions.\n            Command: {command}\n            Output JSON with actions.\n            """,\n            \'safety_first\': """\n            SAFETY-CRITICAL: Convert command to safe robot actions.\n            Command: {command}\n            Ensure all actions include safety checks.\n            Output JSON with actions and safety verifications.\n            """\n        }\n    \n    def test_prompt_effectiveness(self, prompt_template: str, test_commands: List[str]):\n        """\n        Test how well a prompt works with various commands\n        """\n        # Implementation would test the prompt against LLM\n        pass\n'})}),"\n",(0,i.jsx)(e.h2,{id:"7-worked-example-black-box-to-glass-box-understanding",children:"7. Worked Example: Black-Box to Glass-Box Understanding"}),"\n",(0,i.jsx)(e.h3,{id:"71-black-box-view",children:"7.1 Black-Box View"}),"\n",(0,i.jsx)(e.p,{children:"From the outside, the LLM task planning system appears as:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:'Input: "Go to the kitchen and bring me the red cup"\nOutput: Navigation \u2192 Perception \u2192 Manipulation action sequence\n'})}),"\n",(0,i.jsx)(e.h3,{id:"72-glass-box-view-complete-implementation",children:"7.2 Glass-Box View: Complete Implementation"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# Complete LLM task planning implementation\nclass CompleteLLMTaskPlanner:\n    """\n    Complete implementation integrating all LLM task planning components\n    """\n    \n    def __init__(self):\n        self.logger = EducationalLogger("complete_llm_planner")\n        self.metrics = MetricsCollector(self.logger)\n        self.error_handler = EducationalErrorHandler()\n        \n        # Initialize all components\n        self.prompt_engineer = RoboticsPromptEngineer()\n        self.llm_service = LLMIntegrationService()\n        self.action_generator = ActionSequenceGenerator()\n        self.safety_validator = SafetyAwarePrompter()\n        \n        self.logger.info("CompleteLLMTaskPlanner", "__init__", "Complete LLM planner initialized")\n    \n    def plan_task(self, command: str, environment_context: dict = None) -> ActionSequence:\n        """\n        Complete task planning pipeline\n        """\n        try:\n            self.logger.info("CompleteLLMTaskPlanner", "plan_task", "Starting task planning", {\n                \'command\': command\n            })\n            \n            # Step 1: Create safety-aware prompt\n            system_prompt, user_prompt = self.safety_validator.create_safe_task_prompt(command)\n            \n            # Step 2: Process through LLM service\n            action_sequence = self.llm_service.process_natural_language_command(\n                user_prompt, \n                environment_context\n            )\n            \n            # Step 3: Validate safety constraints\n            if not self._validate_safety_constraints(action_sequence):\n                self.logger.warning("CompleteLLMTaskPlanner", "plan_task", \n                                  "Safety validation failed, generating safe fallback")\n                action_sequence = self._generate_safe_fallback(command)\n            \n            # Step 4: Log completion metrics\n            self.metrics.record_metric(\'tasks_planned\', 1)\n            self.logger.info("CompleteLLMTaskPlanner", "plan_task", "Task planning completed", {\n                \'action_count\': len(action_sequence.commands),\n                \'status\': action_sequence.status\n            })\n            \n            return action_sequence\n            \n        except Exception as e:\n            self.error_handler.handle_error(\n                e,\n                context="plan_task",\n                suggested_fix="Check task planning pipeline",\n                learning_objective="Handle complete planning pipeline errors"\n            )\n            return self._generate_error_fallback(str(e))\n    \n    def _validate_safety_constraints(self, action_sequence: ActionSequence) -> bool:\n        """\n        Validate that action sequence meets safety constraints\n        """\n        # Check for potentially unsafe actions\n        for command in action_sequence.commands:\n            action_type = command.get(\'action\', \'\')\n            params = command.get(\'parameters\', {})\n            \n            # Check for unsafe navigation\n            if action_type == \'navigation\':\n                destination = params.get(\'destination\', \'\').lower()\n                if destination in [\'unknown\', \'undefined\', \'\']:\n                    return False\n            \n            # Check for unsafe manipulation\n            elif action_type == \'manipulation\':\n                obj = params.get(\'object\', \'\').lower()\n                if obj in [\'unknown\', \'undefined\', \'\']:\n                    return False\n        \n        return True\n    \n    def _generate_safe_fallback(self, command: str) -> ActionSequence:\n        """\n        Generate a safe fallback action sequence\n        """\n        return ActionSequence(\n            commands=[{\n                \'action\': \'communication\',\n                \'parameters\': {\'message\': f\'Unable to safely execute command: {command}\'}\n            }],\n            context={\'fallback\': True, \'original_command\': command},\n            status=\'fallback\',\n            created_at=datetime.now()\n        )\n    \n    def _generate_error_fallback(self, error_msg: str) -> ActionSequence:\n        """\n        Generate an error fallback action sequence\n        """\n        return ActionSequence(\n            commands=[{\n                \'action\': \'communication\',\n                \'parameters\': {\'message\': f\'Planning error: {error_msg}\'}\n            }],\n            context={\'error\': True, \'error_message\': error_msg},\n            status=\'error\',\n            created_at=datetime.now()\n        )\n\n# Example usage\nif __name__ == "__main__":\n    planner = CompleteLLMTaskPlanner()\n    \n    # Test command\n    command = "Go to the kitchen and bring me the red cup"\n    context = {"room_map": "available", "object_locations": "known"}\n    \n    sequence = planner.plan_task(command, context)\n    print(f"Generated {len(sequence.commands)} actions for: {command}")\n    for i, action in enumerate(sequence.commands):\n        print(f"  {i+1}. {action[\'action\']}: {action.get(\'parameters\', {})}")\n'})}),"\n",(0,i.jsx)(e.h2,{id:"8-tiered-assessments",children:"8. Tiered Assessments"}),"\n",(0,i.jsx)(e.h3,{id:"tier-1-basic-comprehension",children:"Tier 1: Basic Comprehension"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsx)(e.li,{children:"Explain the role of LLMs in robotics task planning"}),"\n",(0,i.jsx)(e.li,{children:"Identify the key components of the LLM integration system"}),"\n",(0,i.jsx)(e.li,{children:"List the safety considerations for LLM-based planning"}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"tier-2-application",children:"Tier 2: Application"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsx)(e.li,{children:"Implement a basic LLM client for robotics commands"}),"\n",(0,i.jsx)(e.li,{children:"Create a prompt template for navigation tasks"}),"\n",(0,i.jsx)(e.li,{children:"Design a simple action sequence generator"}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"tier-3-analysis-and-synthesis",children:"Tier 3: Analysis and Synthesis"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsx)(e.li,{children:"Analyze the trade-offs between different LLM models for robotics"}),"\n",(0,i.jsx)(e.li,{children:"Design a comprehensive safety validation system for LLM outputs"}),"\n",(0,i.jsx)(e.li,{children:"Evaluate the reliability of LLM-generated action sequences"}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"9-citations-and-references",children:"9. Citations and References"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsx)(e.p,{children:'Brown, T., et al. (2020). "Language Models are Few-Shot Learners." Advances in Neural Information Processing Systems, 33.'}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsx)(e.p,{children:'Achiam, J., et al. (2023). "GPT-4 Technical Report." OpenAI.'}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsx)(e.p,{children:'Meta. (2023). "Llama 2: Open Foundation and Fine-tuned Chat Models." Meta AI.'}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsx)(e.p,{children:'Touvron, H., et al. (2023). "LLaMA: Open and Efficient Foundation Language Models." Meta AI.'}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsx)(e.p,{children:'IBM. (2023). "Foundation Model for Robot Learning." IBM Research.'}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsx)(e.p,{children:'NVIDIA. (2023). "Foundation Models for Embodied AI." NVIDIA Technical Report.'}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsx)(e.p,{children:'OpenAI. (2023). "Robot Operating with LLMs: Language Model Guided Robot Execution." OpenAI Robotics.'}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsx)(e.p,{children:'Team, O. (2023). "Ollama: Run LLMs locally." Ollama Documentation.'}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"10-summary",children:"10. Summary"}),"\n",(0,i.jsx)(e.p,{children:"This chapter has covered the implementation of LLM-based task planning for the VLA system. Key concepts include:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Open-source LLM integration using Ollama for privacy-compliant processing"}),"\n",(0,i.jsx)(e.li,{children:"Specialized prompt engineering for robotics applications"}),"\n",(0,i.jsx)(e.li,{children:"Safety-aware planning with validation and verification"}),"\n",(0,i.jsx)(e.li,{children:"ROS 2 integration for action execution"}),"\n",(0,i.jsx)(e.li,{children:"Action sequence generation from natural language commands"}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:"The system provides a foundation for converting natural language commands to executable robot actions while maintaining safety and reliability."}),"\n",(0,i.jsx)(e.h2,{id:"11-next-steps",children:"11. Next Steps"}),"\n",(0,i.jsx)(e.p,{children:"In the following chapters, we will explore:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Multi-modal integration combining vision and language"}),"\n",(0,i.jsx)(e.li,{children:"Complete autonomous humanoid system integration"}),"\n",(0,i.jsx)(e.li,{children:"Advanced perception and manipulation techniques"}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:"This LLM task planning foundation will serve as the intelligence layer for the complete VLA system."})]})}function m(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(d,{...n})}):d(n)}},8453:(n,e,t)=>{t.d(e,{R:()=>r,x:()=>s});var a=t(6540);const i={},o=a.createContext(i);function r(n){const e=a.useContext(o);return a.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:r(n.components),a.createElement(o.Provider,{value:e},n.children)}}}]);