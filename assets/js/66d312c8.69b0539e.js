"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[584],{7146:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>m,frontMatter:()=>o,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"nvidia-isaac/sim-to-real-transfer","title":"Sim-to-Real Transfer Techniques","description":"Learning Objectives","source":"@site/docs/03-nvidia-isaac/04-sim-to-real-transfer.md","sourceDirName":"03-nvidia-isaac","slug":"/nvidia-isaac/sim-to-real-transfer","permalink":"/nvidia-isaac/sim-to-real-transfer","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/03-nvidia-isaac/04-sim-to-real-transfer.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"Sim-to-Real Transfer Techniques"},"sidebar":"moduleSidebar","previous":{"title":"Nav2 for Bipedal Humanoids","permalink":"/nvidia-isaac/nav2-bipedal-locomotion"},"next":{"title":"Chapter 1: Voice-to-Action using OpenAI Whisper (Local Implementation)","permalink":"/vla/voice-to-action-with-whisper"}}');var a=i(4848),s=i(8453);const o={sidebar_position:4,title:"Sim-to-Real Transfer Techniques"},r="Sim-to-Real Transfer Techniques",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction",id:"introduction",level:2},{value:"Theory: Reality Gap and Transfer Learning",id:"theory-reality-gap-and-transfer-learning",level:2},{value:"Sources of Reality Gap",id:"sources-of-reality-gap",level:3},{value:"Domain Randomization Theory",id:"domain-randomization-theory",level:3},{value:"System Identification for Reality Gap Modeling",id:"system-identification-for-reality-gap-modeling",level:3},{value:"Practice: Implementing Sim-to-Real Transfer Techniques",id:"practice-implementing-sim-to-real-transfer-techniques",level:2},{value:"Domain Randomization Implementation",id:"domain-randomization-implementation",level:3},{value:"Reality Gap Compensation Controller",id:"reality-gap-compensation-controller",level:3},{value:"System Identification Node",id:"system-identification-node",level:3},{value:"Sim-to-Real Transfer Validation",id:"sim-to-real-transfer-validation",level:3},{value:"Launch File for Complete Transfer System",id:"launch-file-for-complete-transfer-system",level:3},{value:"Active Learning Exercise",id:"active-learning-exercise",level:2},{value:"Worked Example: Black-box to Glass-box - Complete Sim-to-Real Transfer System",id:"worked-example-black-box-to-glass-box---complete-sim-to-real-transfer-system",level:2},{value:"Black-box View",id:"black-box-view",level:3},{value:"Glass-box Implementation",id:"glass-box-implementation",level:3},{value:"Understanding the Implementation",id:"understanding-the-implementation",level:3},{value:"Tiered Assessments",id:"tiered-assessments",level:2},{value:"Tier 1: Basic Understanding",id:"tier-1-basic-understanding",level:3},{value:"Tier 2: Application",id:"tier-2-application",level:3},{value:"Tier 3: Analysis and Synthesis",id:"tier-3-analysis-and-synthesis",level:3},{value:"Mermaid Diagram",id:"mermaid-diagram",level:2},{value:"Summary",id:"summary",level:2},{value:"References",id:"references",level:2}];function d(n){const e={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"sim-to-real-transfer-techniques",children:"Sim-to-Real Transfer Techniques"})}),"\n",(0,a.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,a.jsx)(e.p,{children:"By the end of this chapter, students will be able to:"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsx)(e.li,{children:"Implement domain randomization strategies to improve sim-to-real transfer"}),"\n",(0,a.jsx)(e.li,{children:"Apply system identification techniques to model sim-to-real differences"}),"\n",(0,a.jsx)(e.li,{children:"Design adaptive control systems that handle reality gap compensation"}),"\n",(0,a.jsx)(e.li,{children:"Validate simulation accuracy against real-world robot performance"}),"\n",(0,a.jsx)(e.li,{children:"Implement sensor fusion techniques to bridge sim-to-real perception differences"}),"\n",(0,a.jsx)(e.li,{children:"Develop robust control policies that generalize from simulation to reality"}),"\n",(0,a.jsx)(e.li,{children:"Evaluate and quantify sim-to-real transfer performance metrics"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"introduction",children:"Introduction"}),"\n",(0,a.jsx)(e.p,{children:"Sim-to-real transfer represents one of the most significant challenges in robotics research and development. While simulation provides a safe, controllable, and cost-effective environment for developing and testing robotic systems, the reality gap\u2014the difference between simulated and real-world behavior\u2014can significantly impact the performance of systems that work well in simulation but fail when deployed on physical robots."}),"\n",(0,a.jsx)(e.p,{children:"For humanoid robots, the reality gap is particularly challenging due to the complex dynamics of bipedal locomotion, intricate mechanical systems with many degrees of freedom, and the need for precise balance control. The high-dimensional action and observation spaces of humanoid robots amplify small discrepancies between simulation and reality, making successful sim-to-real transfer a critical capability for practical humanoid robot deployment."}),"\n",(0,a.jsx)(e.p,{children:"The goal of sim-to-real transfer techniques is to develop controllers, perception systems, and planning algorithms in simulation that perform effectively on real robots. This involves understanding and mitigating the sources of the reality gap, including modeling inaccuracies, sensor noise differences, actuator dynamics, environmental variations, and unmodeled physical phenomena."}),"\n",(0,a.jsx)(e.h2,{id:"theory-reality-gap-and-transfer-learning",children:"Theory: Reality Gap and Transfer Learning"}),"\n",(0,a.jsx)(e.h3,{id:"sources-of-reality-gap",children:"Sources of Reality Gap"}),"\n",(0,a.jsx)(e.p,{children:"The reality gap in humanoid robotics stems from several sources:"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Modeling Inaccuracies"}),": Incomplete or simplified physical models in simulation"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Parameter Uncertainty"}),": Unknown or changing physical parameters (mass, friction, etc.)"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Actuator Dynamics"}),": Differences in motor response, backlash, and compliance"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Sensor Noise"}),": Different noise characteristics between simulated and real sensors"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Environmental Factors"}),": Unmodeled effects like air resistance, surface compliance"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Hardware Limitations"}),": Joint limits, computational delays, and mechanical wear"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"domain-randomization-theory",children:"Domain Randomization Theory"}),"\n",(0,a.jsx)(e.p,{children:"Domain randomization is a technique that introduces controlled variations in the simulation environment to improve the robustness of learned policies. The theory behind domain randomization is based on the idea that if a policy can perform well across a wide range of randomized conditions, it will be more likely to perform well in the real world, which can be viewed as just another randomization of the simulation parameters."}),"\n",(0,a.jsx)(e.p,{children:"The key insight is that instead of trying to match the simulation exactly to reality (which is often impossible), we randomize the simulation parameters to cover the range of possible real-world conditions."}),"\n",(0,a.jsx)(e.h3,{id:"system-identification-for-reality-gap-modeling",children:"System Identification for Reality Gap Modeling"}),"\n",(0,a.jsx)(e.p,{children:"System identification techniques can be used to model the differences between simulation and reality. This involves:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Parameter Estimation"}),": Identifying unknown physical parameters"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Model Error Correction"}),": Learning corrections to simulation models"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Adaptive Control"}),": Adjusting control parameters based on real-world performance"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"practice-implementing-sim-to-real-transfer-techniques",children:"Practice: Implementing Sim-to-Real Transfer Techniques"}),"\n",(0,a.jsx)(e.h3,{id:"domain-randomization-implementation",children:"Domain Randomization Implementation"}),"\n",(0,a.jsx)(e.p,{children:"Let's create a comprehensive domain randomization system for humanoid robot simulation:"}),"\n",(0,a.jsxs)(e.p,{children:["Create ",(0,a.jsx)(e.code,{children:"~/isaac_sim_projects/sim_to_real_transfer/domain_randomization_config.yaml"}),":"]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-yaml",children:'# Domain Randomization Configuration for Sim-to-Real Transfer\n\nrandomization:\n  # Robot physical parameters\n  robot_parameters:\n    enabled: true\n    parameters:\n      # Mass variations\n      link_mass_range: [0.8, 1.2]  # \xb120% of nominal mass\n      # Inertia variations\n      inertia_scale_range: [0.9, 1.1]\n      # Friction variations\n      joint_friction_range: [0.0, 0.1]\n      joint_damping_range: [0.1, 0.5]\n      # Gear ratio variations (for actuator modeling)\n      gear_ratio_range: [0.95, 1.05]\n\n  # Sensor noise modeling\n  sensor_noise:\n    enabled: true\n    parameters:\n      # IMU noise parameters\n      imu:\n        accelerometer_noise_density: [0.01, 0.03]  # Realistic range\n        gyroscope_noise_density: [0.0008, 0.0015]\n        accelerometer_random_walk: [0.0004, 0.0008]\n        gyroscope_random_walk: [3e-06, 6e-06]\n        bias_correlation_time: [100, 1000]\n\n      # Camera noise parameters\n      camera:\n        rgb_noise_std: [0.001, 0.01]\n        depth_noise_std: [0.001, 0.005]\n        camera_delay_range: [0.01, 0.05]  # 10-50ms delay\n\n      # LiDAR noise parameters\n      lidar:\n        range_noise_std: [0.01, 0.05]\n        angular_noise_std: [0.001, 0.005]\n\n  # Actuator dynamics\n  actuator_dynamics:\n    enabled: true\n    parameters:\n      # Motor dynamics\n      motor_time_constant_range: [0.01, 0.05]  # Time constant\n      motor_efficiency_range: [0.7, 0.95]      # Efficiency factor\n      # Torque limits (as percentage of maximum)\n      torque_limit_range: [0.8, 1.0]\n      # Position tracking error\n      position_error_std: [0.005, 0.02]  # radians\n\n  # Environmental factors\n  environment:\n    enabled: true\n    parameters:\n      # Gravity variations (for different locations)\n      gravity_range: [9.78, 9.83]  # m/s^2\n      # Surface properties\n      ground_friction_range: [0.3, 0.9]\n      ground_restitution_range: [0.05, 0.2]\n      # Air resistance (simplified)\n      air_resistance_coeff_range: [0.0, 0.1]\n\n  # Control timing variations\n  control_timing:\n    enabled: true\n    parameters:\n      # Control loop frequency variations\n      control_frequency_range: [90, 110]  # Hz (nominal 100Hz)\n      # Sensor update timing variations\n      sensor_frequency_range: [95, 105]   # Hz\n      # Communication delays\n      control_delay_range: [0.005, 0.02]  # 5-20ms\n\n# Training curriculum settings\ncurriculum:\n  # Start with low randomization and gradually increase\n  enable_curriculum: true\n  stages:\n    - name: "initial"\n      duration: 1000000  # steps\n      randomization_strength: 0.1\n    - name: "progressive"\n      duration: 2000000  # steps\n      randomization_strength: 0.5\n    - name: "full_randomization"\n      duration: 3000000  # steps\n      randomization_strength: 1.0\n\n# Validation settings\nvalidation:\n  # Parameters for testing on real robot\n  real_robot_params:\n    # Real robot parameters for validation\n    mass_scaling: 1.0\n    friction_coefficient: 0.7\n    actuator_latency: 0.015  # seconds\n    sensor_noise_multiplier: 1.0\n'})}),"\n",(0,a.jsx)(e.h3,{id:"reality-gap-compensation-controller",children:"Reality Gap Compensation Controller"}),"\n",(0,a.jsxs)(e.p,{children:["Create ",(0,a.jsx)(e.code,{children:"~/ros2_ws/src/sim_to_real_transfer/src/reality_gap_compensation.cpp"}),":"]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-cpp",children:'#include <rclcpp/rclcpp.hpp>\n#include <sensor_msgs/msg/joint_state.hpp>\n#include <geometry_msgs/msg/twist.hpp>\n#include <std_msgs/msg/float64_multi_array.hpp>\n#include <control_msgs/msg/joint_trajectory_controller_state.hpp>\n#include <vector>\n#include <memory>\n#include <cmath>\n\nclass RealityGapCompensation : public rclcpp::Node\n{\npublic:\n    RealityGapCompensation() : Node("reality_gap_compensation")\n    {\n        // Declare parameters\n        this->declare_parameter<std::string>("robot_namespace", "/simple_humanoid");\n        this->declare_parameter<double>("compensation_rate", 100.0);\n        this->declare_parameter<bool>("enable_adaptive_compensation", true);\n        this->declare_parameter<double>("learning_rate", 0.01);\n        this->declare_parameter<double>("max_compensation", 0.1);\n\n        // Get parameters\n        robot_namespace_ = this->get_parameter("robot_namespace").as_string();\n        compensation_rate_ = this->get_parameter("compensation_rate").as_double();\n        enable_adaptive_ = this->get_parameter("enable_adaptive_compensation").as_bool();\n        learning_rate_ = this->get_parameter("learning_rate").as_double();\n        max_compensation_ = this->get_parameter("max_compensation").as_double();\n\n        // Create subscribers\n        sim_joint_sub_ = this->create_subscription<sensor_msgs::msg::JointState>(\n            robot_namespace_ + "/sim/joint_states",\n            10,\n            std::bind(&RealityGapCompensation::simJointCallback, this, std::placeholders::_1));\n\n        real_joint_sub_ = this->create_subscription<sensor_msgs::msg::JointState>(\n            robot_namespace_ + "/real/joint_states",\n            10,\n            std::bind(&RealityGapCompensation::realJointCallback, this, std::placeholders::_1));\n\n        sim_cmd_sub_ = this->create_subscription<std_msgs::msg::Float64MultiArray>(\n            robot_namespace_ + "/sim/joint_commands",\n            10,\n            std::bind(&RealityGapCompensation::simCommandCallback, this, std::placeholders::_1));\n\n        // Create publishers\n        compensated_cmd_pub_ = this->create_publisher<std_msgs::msg::Float64MultiArray>(\n            robot_namespace_ + "/compensated/joint_commands",\n            10);\n\n        compensation_params_pub_ = this->create_publisher<std_msgs::msg::Float64MultiArray>(\n            robot_namespace_ + "/reality_gap/compensation_params",\n            10);\n\n        // Initialize compensation parameters\n        initializeCompensation();\n\n        // Create timer for compensation update\n        compensation_timer_ = this->create_timer(\n            std::chrono::duration<double>(1.0 / compensation_rate_),\n            std::bind(&RealityGapCompensation::compensationCallback, this));\n\n        RCLCPP_INFO(this->get_logger(), "Reality Gap Compensation node initialized");\n    }\n\nprivate:\n    void simJointCallback(const sensor_msgs::msg::JointState::SharedPtr msg)\n    {\n        sim_joint_state_ = *msg;\n        sim_data_received_ = true;\n    }\n\n    void realJointCallback(const sensor_msgs::msg::JointState::SharedPtr msg)\n    {\n        real_joint_state_ = *msg;\n        real_data_received_ = true;\n    }\n\n    void simCommandCallback(const std_msgs::msg::Float64MultiArray::SharedPtr msg)\n    {\n        sim_commands_ = *msg;\n        command_received_ = true;\n    }\n\n    void initializeCompensation()\n    {\n        // Initialize compensation parameters based on joint names\n        if (sim_data_received_ && !compensation_initialized_) {\n            compensation_params_.resize(sim_joint_state_.position.size(), 0.0);\n            compensation_velocity_.resize(sim_joint_state_.position.size(), 0.0);\n            last_error_.resize(sim_joint_state_.position.size(), 0.0);\n\n            compensation_initialized_ = true;\n            RCLCPP_INFO(this->get_logger(), "Compensation initialized with %zu joints",\n                       sim_joint_state_.position.size());\n        }\n    }\n\n    void compensationCallback()\n    {\n        if (!sim_data_received_ || !real_data_received_ || !command_received_) {\n            return;\n        }\n\n        // Compute reality gap compensation\n        if (enable_adaptive_) {\n            computeAdaptiveCompensation();\n        } else {\n            computeStaticCompensation();\n        }\n\n        // Apply compensation to commands\n        applyCompensation();\n\n        // Publish compensation parameters for monitoring\n        publishCompensationParams();\n    }\n\n    void computeAdaptiveCompensation()\n    {\n        if (!compensation_initialized_) {\n            initializeCompensation();\n            return;\n        }\n\n        // Compute position error between sim and real\n        for (size_t i = 0; i < std::min(real_joint_state_.position.size(),\n                                       compensation_params_.size()); ++i) {\n\n            // Find corresponding joint in simulation data\n            int sim_idx = -1;\n            for (size_t j = 0; j < sim_joint_state_.name.size(); ++j) {\n                if (sim_joint_state_.name[j] == real_joint_state_.name[i]) {\n                    sim_idx = j;\n                    break;\n                }\n            }\n\n            if (sim_idx >= 0 && sim_idx < static_cast<int>(sim_joint_state_.position.size())) {\n                // Calculate position error\n                double error = real_joint_state_.position[i] - sim_joint_state_.position[sim_idx];\n\n                // Update compensation using gradient descent\n                compensation_params_[i] -= learning_rate_ * error;\n\n                // Apply bounds to compensation\n                compensation_params_[i] = std::max(-max_compensation_,\n                                                 std::min(max_compensation_, compensation_params_[i]));\n            }\n        }\n    }\n\n    void computeStaticCompensation()\n    {\n        // Static compensation based on pre-computed parameters\n        // In a real implementation, these would be learned through system identification\n        static bool first_run = true;\n        if (first_run) {\n            // Initialize with typical reality gap values\n            for (auto& param : compensation_params_) {\n                param = 0.0; // Start with no compensation\n            }\n            first_run = false;\n        }\n    }\n\n    void applyCompensation()\n    {\n        if (!command_received_ || sim_commands_.data.empty()) {\n            return;\n        }\n\n        // Apply compensation to simulation commands\n        auto compensated_commands = sim_commands_;\n\n        for (size_t i = 0; i < std::min(compensated_commands.data.size(),\n                                       compensation_params_.size()); ++i) {\n            compensated_commands.data[i] += compensation_params_[i];\n        }\n\n        // Publish compensated commands\n        compensated_cmd_pub_->publish(compensated_commands);\n    }\n\n    void publishCompensationParams()\n    {\n        std_msgs::msg::Float64MultiArray params_msg;\n        params_msg.data = compensation_params_;\n\n        compensation_params_pub_->publish(params_msg);\n    }\n\n    // ROS components\n    rclcpp::Subscription<sensor_msgs::msg::JointState>::SharedPtr sim_joint_sub_;\n    rclcpp::Subscription<sensor_msgs::msg::JointState>::SharedPtr real_joint_sub_;\n    rclcpp::Subscription<std_msgs::msg::Float64MultiArray>::SharedPtr sim_cmd_sub_;\n    rclcpp::Publisher<std_msgs::msg::Float64MultiArray>::SharedPtr compensated_cmd_pub_;\n    rclcpp::Publisher<std_msgs::msg::Float64MultiArray>::SharedPtr compensation_params_pub_;\n    rclcpp::TimerBase::SharedPtr compensation_timer_;\n\n    // Data storage\n    sensor_msgs::msg::JointState sim_joint_state_;\n    sensor_msgs::msg::JointState real_joint_state_;\n    std_msgs::msg::Float64MultiArray sim_commands_;\n\n    // Compensation parameters\n    std::vector<double> compensation_params_;\n    std::vector<double> compensation_velocity_;\n    std::vector<double> last_error_;\n\n    // Flags\n    bool sim_data_received_ = false;\n    bool real_data_received_ = false;\n    bool command_received_ = false;\n    bool compensation_initialized_ = false;\n\n    // Configuration\n    std::string robot_namespace_;\n    double compensation_rate_;\n    bool enable_adaptive_;\n    double learning_rate_;\n    double max_compensation_;\n};\n\nint main(int argc, char * argv[])\n{\n    rclcpp::init(argc, argv);\n    rclcpp::spin(std::make_shared<RealityGapCompensation>());\n    rclcpp::shutdown();\n    return 0;\n}\n'})}),"\n",(0,a.jsx)(e.h3,{id:"system-identification-node",children:"System Identification Node"}),"\n",(0,a.jsxs)(e.p,{children:["Create ",(0,a.jsx)(e.code,{children:"~/ros2_ws/src/sim_to_real_transfer/src/system_identification.cpp"}),":"]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-cpp",children:'#include <rclcpp/rclcpp.hpp>\n#include <sensor_msgs/msg/joint_state.hpp>\n#include <geometry_msgs/msg/twist.hpp>\n#include <std_msgs/msg/float64_multi_array.hpp>\n#include <tf2/LinearMath/Transform.h>\n#include <Eigen/Dense>\n#include <vector>\n#include <deque>\n#include <memory>\n\nclass SystemIdentification : public rclcpp::Node\n{\npublic:\n    SystemIdentification() : Node("system_identification")\n    {\n        // Declare parameters\n        this->declare_parameter<std::string>("robot_namespace", "/simple_humanoid");\n        this->declare_parameter<double>("identification_rate", 50.0);\n        this->declare_parameter<int>("window_size", 1000);\n        this->declare_parameter<double>("excitation_amplitude", 0.1);\n        this->declare_parameter<double>("excitation_frequency", 1.0);\n\n        // Get parameters\n        robot_namespace_ = this->get_parameter("robot_namespace").as_string();\n        identification_rate_ = this->get_parameter("identification_rate").as_double();\n        window_size_ = this->get_parameter("window_size").as_integer();\n        excitation_amplitude_ = this->get_parameter("excitation_amplitude").as_double();\n        excitation_frequency_ = this->get_parameter("excitation_frequency").as_double();\n\n        // Create subscribers\n        sim_joint_sub_ = this->create_subscription<sensor_msgs::msg::JointState>(\n            robot_namespace_ + "/sim/joint_states",\n            10,\n            std::bind(&SystemIdentification::simJointCallback, this, std::placeholders::_1));\n\n        real_joint_sub_ = this->create_subscription<sensor_msgs::msg::JointState>(\n            robot_namespace_ + "/real/joint_states",\n            10,\n            std::bind(&SystemIdentification::realJointCallback, this, std::placeholders::_1));\n\n        sim_cmd_sub_ = this->create_subscription<std_msgs::msg::Float64MultiArray>(\n            robot_namespace_ + "/sim/joint_commands",\n            10,\n            std::bind(&SystemIdentification::simCommandCallback, this, std::placeholders::_1));\n\n        // Create publishers\n        excitation_cmd_pub_ = this->create_publisher<std_msgs::msg::Float64MultiArray>(\n            robot_namespace_ + "/excitation_commands",\n            10);\n\n        model_params_pub_ = this->create_publisher<std_msgs::msg::Float64MultiArray>(\n            robot_namespace_ + "/identified_model_params",\n            10);\n\n        // Initialize data structures\n        initializeDataStructures();\n\n        // Create timer for system identification\n        identification_timer_ = this->create_timer(\n            std::chrono::duration<double>(1.0 / identification_rate_),\n            std::bind(&SystemIdentification::identificationCallback, this));\n\n        RCLCPP_INFO(this->get_logger(), "System Identification node initialized");\n    }\n\nprivate:\n    void initializeDataStructures()\n    {\n        // Initialize data windows for system identification\n        sim_data_window_.resize(window_size_);\n        real_data_window_.resize(window_size_);\n        cmd_data_window_.resize(window_size_);\n\n        current_index_ = 0;\n        data_collected_ = false;\n    }\n\n    void simJointCallback(const sensor_msgs::msg::JointState::SharedPtr msg)\n    {\n        if (joint_names_.empty()) {\n            joint_names_ = msg->name;\n        }\n        sim_joint_state_ = *msg;\n    }\n\n    void realJointCallback(const sensor_msgs::msg::JointState::SharedPtr msg)\n    {\n        if (joint_names_.empty()) {\n            joint_names_ = msg->name;\n        }\n        real_joint_state_ = *msg;\n    }\n\n    void simCommandCallback(const std_msgs::msg::Float64MultiArray::SharedPtr msg)\n    {\n        sim_commands_ = *msg;\n    }\n\n    void identificationCallback()\n    {\n        if (joint_names_.empty() || sim_joint_state_.name.empty() || real_joint_state_.name.empty()) {\n            return;\n        }\n\n        // Collect data for system identification\n        collectData();\n\n        // Generate excitation signal\n        generateExcitationSignal();\n\n        // If enough data collected, perform system identification\n        if (data_collected_) {\n            performSystemIdentification();\n        }\n    }\n\n    void collectData()\n    {\n        // Store current data in window\n        SystemData data;\n        data.sim_positions = sim_joint_state_.position;\n        data.real_positions = real_joint_state_.position;\n        data.commands = sim_commands_.data;\n        data.timestamp = this->get_clock()->now();\n\n        sim_data_window_[current_index_] = data.sim_positions;\n        real_data_window_[current_index_] = data.real_positions;\n        cmd_data_window_[current_index_] = data.commands;\n\n        current_index_ = (current_index_ + 1) % window_size_;\n\n        // Check if window is full\n        if (current_index_ == 0 && !data_collected_) {\n            data_collected_ = true;\n        }\n    }\n\n    void generateExcitationSignal()\n    {\n        // Generate persistently exciting signal for system identification\n        auto excitation_msg = std_msgs::msg::Float64MultiArray();\n\n        if (sim_commands_.data.empty()) {\n            excitation_msg.data.resize(joint_names_.size(), 0.0);\n        } else {\n            excitation_msg.data = sim_commands_.data;\n        }\n\n        // Add sinusoidal excitation to each joint\n        double time = this->get_clock()->now().seconds();\n        for (size_t i = 0; i < excitation_msg.data.size(); ++i) {\n            double excitation = excitation_amplitude_ *\n                              std::sin(2.0 * M_PI * excitation_frequency_ * time +\n                                      static_cast<double>(i) * M_PI / 4.0);\n            excitation_msg.data[i] += excitation;\n        }\n\n        excitation_cmd_pub_->publish(excitation_msg);\n    }\n\n    void performSystemIdentification()\n    {\n        // Perform system identification to find model parameters\n        // This is a simplified example - real implementation would be more complex\n\n        if (!sim_data_window_.empty() && !real_data_window_.empty()) {\n            // Calculate mean differences between sim and real\n            std::vector<double> position_diffs(joint_names_.size(), 0.0);\n\n            for (size_t i = 0; i < joint_names_.size(); ++i) {\n                double diff_sum = 0.0;\n                int valid_count = 0;\n\n                for (int j = 0; j < window_size_; ++j) {\n                    if (i < sim_data_window_[j].size() && i < real_data_window_[j].size()) {\n                        diff_sum += real_data_window_[j][i] - sim_data_window_[j][i];\n                        valid_count++;\n                    }\n                }\n\n                if (valid_count > 0) {\n                    position_diffs[i] = diff_sum / valid_count;\n                }\n            }\n\n            // Publish identified model parameters\n            publishModelParameters(position_diffs);\n        }\n    }\n\n    void publishModelParameters(const std::vector<double>& params)\n    {\n        auto params_msg = std_msgs::msg::Float64MultiArray();\n        params_msg.data = params;\n\n        model_params_pub_->publish(params_msg);\n\n        // Log parameters for monitoring\n        std::string param_str = "Model parameters: ";\n        for (double param : params) {\n            param_str += std::to_string(param) + " ";\n        }\n        RCLCPP_DEBUG(this->get_logger(), "%s", param_str.c_str());\n    }\n\n    struct SystemData {\n        std::vector<double> sim_positions;\n        std::vector<double> real_positions;\n        std::vector<double> commands;\n        rclcpp::Time timestamp;\n    };\n\n    // ROS components\n    rclcpp::Subscription<sensor_msgs::msg::JointState>::SharedPtr sim_joint_sub_;\n    rclcpp::Subscription<sensor_msgs::msg::JointState>::SharedPtr real_joint_sub_;\n    rclcpp::Subscription<std_msgs::msg::Float64MultiArray>::SharedPtr sim_cmd_sub_;\n    rclcpp::Publisher<std_msgs::msg::Float64MultiArray>::SharedPtr excitation_cmd_pub_;\n    rclcpp::Publisher<std_msgs::msg::Float64MultiArray>::SharedPtr model_params_pub_;\n    rclcpp::TimerBase::SharedPtr identification_timer_;\n\n    // Data storage\n    sensor_msgs::msg::JointState sim_joint_state_;\n    sensor_msgs::msg::JointState real_joint_state_;\n    std_msgs::msg::Float64MultiArray sim_commands_;\n    std::vector<std::string> joint_names_;\n\n    // System identification data\n    std::vector<std::vector<double>> sim_data_window_;\n    std::vector<std::vector<double>> real_data_window_;\n    std::vector<std::vector<double>> cmd_data_window_;\n    int current_index_;\n    int window_size_;\n    bool data_collected_;\n\n    // Configuration\n    std::string robot_namespace_;\n    double identification_rate_;\n    double excitation_amplitude_;\n    double excitation_frequency_;\n};\n\nint main(int argc, char * argv[])\n{\n    rclcpp::init(argc, argv);\n    rclcpp::spin(std::make_shared<SystemIdentification>());\n    rclcpp::shutdown();\n    return 0;\n}\n'})}),"\n",(0,a.jsx)(e.h3,{id:"sim-to-real-transfer-validation",children:"Sim-to-Real Transfer Validation"}),"\n",(0,a.jsxs)(e.p,{children:["Create ",(0,a.jsx)(e.code,{children:"~/ros2_ws/src/sim_to_real_transfer/src/transfer_validation.cpp"}),":"]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-cpp",children:'#include <rclcpp/rclcpp.hpp>\n#include <sensor_msgs/msg/joint_state.hpp>\n#include <geometry_msgs/msg/pose_stamped.hpp>\n#include <nav_msgs/msg/odometry.hpp>\n#include <std_msgs/msg/float64_multi_array.hpp>\n#include <std_msgs/msg/bool.hpp>\n#include <tf2/LinearMath/Transform.h>\n#include <tf2_geometry_msgs/tf2_geometry_msgs.h>\n#include <vector>\n#include <cmath>\n\nclass TransferValidation : public rclcpp::Node\n{\npublic:\n    TransferValidation() : Node("transfer_validation")\n    {\n        // Declare parameters\n        this->declare_parameter<std::string>("robot_namespace", "/simple_humanoid");\n        this->declare_parameter<double>("validation_rate", 10.0);\n        this->declare_parameter<double>("position_tolerance", 0.05);  // 5cm\n        this->declare_parameter<double>("orientation_tolerance", 0.1); // 0.1 rad\n        this->declare_parameter<double>("velocity_tolerance", 0.1);   // 0.1 m/s\n        this->declare_parameter<int>("validation_window", 100);\n        this->declare_parameter<double>("success_threshold", 0.8);    // 80% success rate\n\n        // Get parameters\n        robot_namespace_ = this->get_parameter("robot_namespace").as_string();\n        validation_rate_ = this->get_parameter("validation_rate").as_double();\n        pos_tolerance_ = this->get_parameter("position_tolerance").as_double();\n        orient_tolerance_ = this->get_parameter("orientation_tolerance").as_double();\n        vel_tolerance_ = this->get_parameter("velocity_tolerance").as_double();\n        validation_window_ = this->get_parameter("validation_window").as_integer();\n        success_threshold_ = this->get_parameter("success_threshold").as_double();\n\n        // Create subscribers\n        sim_pose_sub_ = this->create_subscription<geometry_msgs::msg::PoseStamped>(\n            robot_namespace_ + "/sim/pose",\n            10,\n            std::bind(&TransferValidation::simPoseCallback, this, std::placeholders::_1));\n\n        real_pose_sub_ = this->create_subscription<geometry_msgs::msg::PoseStamped>(\n            robot_namespace_ + "/real/pose",\n            10,\n            std::bind(&TransferValidation::realPoseCallback, this, std::placeholders::_1));\n\n        sim_odom_sub_ = this->create_subscription<nav_msgs::msg::Odometry>(\n            robot_namespace_ + "/sim/odometry",\n            10,\n            std::bind(&TransferValidation::simOdomCallback, this, std::placeholders::_1));\n\n        real_odom_sub_ = this->create_subscription<nav_msgs::msg::Odometry>(\n            robot_namespace_ + "/real/odometry",\n            10,\n            std::bind(&TransferValidation::realOdomCallback, this, std::placeholders::_1));\n\n        // Create publishers\n        transfer_success_pub_ = this->create_publisher<std_msgs::msg::Bool>(\n            robot_namespace_ + "/transfer_success",\n            10);\n\n        validation_metrics_pub_ = this->create_publisher<std_msgs::msg::Float64MultiArray>(\n            robot_namespace_ + "/validation_metrics",\n            10);\n\n        // Initialize validation data\n        validation_results_.resize(validation_window_, false);\n\n        // Create timer for validation\n        validation_timer_ = this->create_timer(\n            std::chrono::duration<double>(1.0 / validation_rate_),\n            std::bind(&TransferValidation::validationCallback, this));\n\n        RCLCPP_INFO(this->get_logger(), "Transfer Validation node initialized");\n    }\n\nprivate:\n    void simPoseCallback(const geometry_msgs::msg::PoseStamped::SharedPtr msg)\n    {\n        sim_pose_ = *msg;\n        sim_pose_received_ = true;\n    }\n\n    void realPoseCallback(const geometry_msgs::msg::PoseStamped::SharedPtr msg)\n    {\n        real_pose_ = *msg;\n        real_pose_received_ = true;\n    }\n\n    void simOdomCallback(const nav_msgs::msg::Odometry::SharedPtr msg)\n    {\n        sim_odom_ = *msg;\n        sim_odom_received_ = true;\n    }\n\n    void realOdomCallback(const nav_msgs::msg::Odometry::SharedPtr msg)\n    {\n        real_odom_ = *msg;\n        real_odom_received_ = true;\n    }\n\n    void validationCallback()\n    {\n        if (!sim_pose_received_ || !real_pose_received_ ||\n            !sim_odom_received_ || !real_odom_received_) {\n            return;\n        }\n\n        // Calculate validation metrics\n        double pos_error = calculatePositionError();\n        double orient_error = calculateOrientationError();\n        double vel_error = calculateVelocityError();\n\n        // Determine if this validation step is successful\n        bool step_success = (pos_error <= pos_tolerance_) &&\n                           (orient_error <= orient_tolerance_) &&\n                           (vel_error <= vel_tolerance_);\n\n        // Update validation window\n        validation_results_[validation_index_] = step_success;\n        validation_index_ = (validation_index_ + 1) % validation_window_;\n\n        // Calculate overall success rate\n        double success_rate = calculateSuccessRate();\n\n        // Publish transfer success status\n        auto success_msg = std_msgs::msg::Bool();\n        success_msg.data = (success_rate >= success_threshold_);\n        transfer_success_pub_->publish(success_msg);\n\n        // Publish validation metrics\n        publishValidationMetrics(pos_error, orient_error, vel_error, success_rate);\n\n        // Log validation results\n        RCLCPP_DEBUG(this->get_logger(),\n            "Validation - Pos Error: %.3f, Orient Error: %.3f, Vel Error: %.3f, "\n            "Success Rate: %.2f%%, Transfer Success: %s",\n            pos_error, orient_error, vel_error, success_rate * 100.0,\n            success_msg.data ? "YES" : "NO");\n    }\n\n    double calculatePositionError()\n    {\n        double dx = sim_pose_.pose.position.x - real_pose_.pose.position.x;\n        double dy = sim_pose_.pose.position.y - real_pose_.pose.position.y;\n        double dz = sim_pose_.pose.position.z - real_pose_.pose.position.z;\n\n        return std::sqrt(dx*dx + dy*dy + dz*dz);\n    }\n\n    double calculateOrientationError()\n    {\n        // Calculate orientation error using quaternion difference\n        tf2::Quaternion sim_quat, real_quat;\n        tf2::fromMsg(sim_pose_.pose.orientation, sim_quat);\n        tf2::fromMsg(real_pose_.pose.orientation, real_quat);\n\n        // Calculate the relative rotation\n        tf2::Quaternion relative_quat = sim_quat.inverse() * real_quat;\n        relative_quat.normalize();\n\n        // Convert to angle\n        double angle = 2.0 * std::acos(std::abs(relative_quat.w()));\n        return angle;\n    }\n\n    double calculateVelocityError()\n    {\n        double lin_dx = sim_odom_.twist.twist.linear.x - real_odom_.twist.twist.linear.x;\n        double lin_dy = sim_odom_.twist.twist.linear.y - real_odom_.twist.twist.linear.y;\n        double lin_dz = sim_odom_.twist.twist.linear.z - real_odom_.twist.twist.linear.z;\n\n        double ang_dx = sim_odom_.twist.twist.angular.x - real_odom_.twist.twist.angular.x;\n        double ang_dy = sim_odom_.twist.twist.angular.y - real_odom_.twist.twist.angular.y;\n        double ang_dz = sim_odom_.twist.twist.angular.z - real_odom_.twist.twist.angular.z;\n\n        double lin_error = std::sqrt(lin_dx*lin_dx + lin_dy*lin_dy + lin_dz*lin_dz);\n        double ang_error = std::sqrt(ang_dx*ang_dx + ang_dy*ang_dy + ang_dz*ang_dz);\n\n        return lin_error + ang_error; // Combined linear and angular velocity error\n    }\n\n    double calculateSuccessRate()\n    {\n        int success_count = 0;\n        for (bool result : validation_results_) {\n            if (result) success_count++;\n        }\n        return static_cast<double>(success_count) / validation_window_;\n    }\n\n    void publishValidationMetrics(double pos_error, double orient_error, double vel_error, double success_rate)\n    {\n        auto metrics_msg = std_msgs::msg::Float64MultiArray();\n        metrics_msg.data = {pos_error, orient_error, vel_error, success_rate};\n\n        validation_metrics_pub_->publish(metrics_msg);\n    }\n\n    // ROS components\n    rclcpp::Subscription<geometry_msgs::msg::PoseStamped>::SharedPtr sim_pose_sub_;\n    rclcpp::Subscription<geometry_msgs::msg::PoseStamped>::SharedPtr real_pose_sub_;\n    rclcpp::Subscription<nav_msgs::msg::Odometry>::SharedPtr sim_odom_sub_;\n    rclcpp::Subscription<nav_msgs::msg::Odometry>::SharedPtr real_odom_sub_;\n    rclcpp::Publisher<std_msgs::msg::Bool>::SharedPtr transfer_success_pub_;\n    rclcpp::Publisher<std_msgs::msg::Float64MultiArray>::SharedPtr validation_metrics_pub_;\n    rclcpp::TimerBase::SharedPtr validation_timer_;\n\n    // Data storage\n    geometry_msgs::msg::PoseStamped sim_pose_, real_pose_;\n    nav_msgs::msg::Odometry sim_odom_, real_odom_;\n\n    // Validation data\n    std::vector<bool> validation_results_;\n    size_t validation_index_ = 0;\n\n    // Flags\n    bool sim_pose_received_ = false;\n    bool real_pose_received_ = false;\n    bool sim_odom_received_ = false;\n    bool real_odom_received_ = false;\n\n    // Configuration\n    std::string robot_namespace_;\n    double validation_rate_;\n    double pos_tolerance_;\n    double orient_tolerance_;\n    double vel_tolerance_;\n    int validation_window_;\n    double success_threshold_;\n};\n\nint main(int argc, char * argv[])\n{\n    rclcpp::init(argc, argv);\n    rclcpp::spin(std::make_shared<TransferValidation>());\n    rclcpp::shutdown();\n    return 0;\n}\n'})}),"\n",(0,a.jsx)(e.h3,{id:"launch-file-for-complete-transfer-system",children:"Launch File for Complete Transfer System"}),"\n",(0,a.jsxs)(e.p,{children:["Create ",(0,a.jsx)(e.code,{children:"~/ros2_ws/src/sim_to_real_transfer/launch/sim_to_real_transfer.launch.py"}),":"]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"import os\nfrom launch import LaunchDescription\nfrom launch.actions import DeclareLaunchArgument, RegisterEventHandler\nfrom launch.event_handlers import OnProcessStart\nfrom launch.substitutions import LaunchConfiguration\nfrom launch_ros.actions import Node\nfrom ament_index_python.packages import get_package_share_directory\n\ndef generate_launch_description():\n    # Declare launch arguments\n    robot_namespace_arg = DeclareLaunchArgument(\n        'robot_namespace',\n        default_value='/simple_humanoid',\n        description='Robot namespace for topics'\n    )\n\n    validation_rate_arg = DeclareLaunchArgument(\n        'validation_rate',\n        default_value='10.0',\n        description='Validation rate in Hz'\n    )\n\n    compensation_rate_arg = DeclareLaunchArgument(\n        'compensation_rate',\n        default_value='100.0',\n        description='Compensation update rate in Hz'\n    )\n\n    # Get launch configurations\n    robot_namespace = LaunchConfiguration('robot_namespace')\n    validation_rate = LaunchConfiguration('validation_rate')\n    compensation_rate = LaunchConfiguration('compensation_rate')\n\n    # Reality gap compensation node\n    reality_gap_compensation = Node(\n        package='sim_to_real_transfer',\n        executable='reality_gap_compensation',\n        name='reality_gap_compensation',\n        parameters=[\n            {\n                'robot_namespace': robot_namespace,\n                'compensation_rate': compensation_rate,\n                'enable_adaptive_compensation': True,\n                'learning_rate': 0.01,\n                'max_compensation': 0.1\n            }\n        ],\n        output='screen'\n    )\n\n    # System identification node\n    system_identification = Node(\n        package='sim_to_real_transfer',\n        executable='system_identification',\n        name='system_identification',\n        parameters=[\n            {\n                'robot_namespace': robot_namespace,\n                'identification_rate': 50.0,\n                'window_size': 1000,\n                'excitation_amplitude': 0.1,\n                'excitation_frequency': 1.0\n            }\n        ],\n        output='screen'\n    )\n\n    # Transfer validation node\n    transfer_validation = Node(\n        package='sim_to_real_transfer',\n        executable='transfer_validation',\n        name='transfer_validation',\n        parameters=[\n            {\n                'robot_namespace': robot_namespace,\n                'validation_rate': validation_rate,\n                'position_tolerance': 0.05,\n                'orientation_tolerance': 0.1,\n                'velocity_tolerance': 0.1,\n                'validation_window': 100,\n                'success_threshold': 0.8\n            }\n        ],\n        output='screen'\n    )\n\n    return LaunchDescription([\n        robot_namespace_arg,\n        validation_rate_arg,\n        compensation_rate_arg,\n        system_identification,\n        reality_gap_compensation,\n        transfer_validation\n    ])\n"})}),"\n",(0,a.jsx)(e.h2,{id:"active-learning-exercise",children:"Active Learning Exercise"}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Exercise: Reality Gap Characterization"})}),"\n",(0,a.jsx)(e.p,{children:"Design an experiment to characterize the reality gap for your humanoid robot:"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Data Collection"}),": Implement a systematic data collection procedure that records both simulation and real-world behavior under identical conditions"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Gap Analysis"}),": Analyze the collected data to identify specific sources of the reality gap (modeling errors, sensor differences, actuator dynamics)"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Compensation Design"}),": Based on your analysis, design and implement a compensation strategy"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Validation"}),": Test your compensation strategy and measure the improvement in sim-to-real transfer performance"]}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"Consider different types of movements (static poses, dynamic walking, balance recovery) and environmental conditions to thoroughly characterize the reality gap."}),"\n",(0,a.jsx)(e.h2,{id:"worked-example-black-box-to-glass-box---complete-sim-to-real-transfer-system",children:"Worked Example: Black-box to Glass-box - Complete Sim-to-Real Transfer System"}),"\n",(0,a.jsx)(e.h3,{id:"black-box-view",children:"Black-box View"}),"\n",(0,a.jsx)(e.p,{children:"We'll create a complete sim-to-real transfer system that learns to compensate for the reality gap between simulation and real humanoid robot behavior. The black-box view is: the system receives simulation and real robot data, learns the differences, and outputs corrected commands that make the real robot behave more like the simulated one."}),"\n",(0,a.jsx)(e.h3,{id:"glass-box-implementation",children:"Glass-box Implementation"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsx)(e.li,{children:(0,a.jsx)(e.strong,{children:"Complete system architecture:"})}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"The implementation includes:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"System identification to model sim-to-real differences"}),"\n",(0,a.jsx)(e.li,{children:"Adaptive compensation to correct for reality gap"}),"\n",(0,a.jsx)(e.li,{children:"Validation system to measure transfer success"}),"\n",(0,a.jsx)(e.li,{children:"Integration with existing simulation and control infrastructure"}),"\n"]}),"\n",(0,a.jsxs)(e.ol,{start:"2",children:["\n",(0,a.jsx)(e.li,{children:(0,a.jsx)(e.strong,{children:"Adaptive learning algorithm:"})}),"\n"]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-cpp",children:"// Example of adaptive compensation learning (conceptual)\nclass AdaptiveCompensator {\npublic:\n    AdaptiveCompensator(double learning_rate = 0.01, double max_compensation = 0.1)\n        : learning_rate_(learning_rate), max_compensation_(max_compensation) {}\n\n    double updateCompensation(double sim_output, double real_output) {\n        // Calculate error between simulation and reality\n        double error = real_output - sim_output;\n\n        // Update compensation parameter using gradient descent\n        compensation_ -= learning_rate_ * error;\n\n        // Apply bounds to prevent overcompensation\n        compensation_ = std::max(-max_compensation_,\n                               std::min(max_compensation_, compensation_));\n\n        return compensation_;\n    }\n\n    double applyCompensation(double sim_command) {\n        return sim_command + compensation_;\n    }\n\nprivate:\n    double compensation_ = 0.0;\n    double learning_rate_;\n    double max_compensation_;\n};\n\n// Multi-joint compensation system\nclass MultiJointCompensator {\npublic:\n    MultiJointCompensator(size_t num_joints) : num_joints_(num_joints) {\n        compensators_.resize(num_joints_);\n        for (auto& compensator : compensators_) {\n            compensator = std::make_unique<AdaptiveCompensator>();\n        }\n    }\n\n    std::vector<double> compensateCommands(\n        const std::vector<double>& sim_commands,\n        const std::vector<double>& real_positions,\n        const std::vector<double>& sim_positions) {\n\n        std::vector<double> compensated_commands(sim_commands.size());\n\n        for (size_t i = 0; i < std::min({sim_commands.size(),\n                                       real_positions.size(),\n                                       sim_positions.size(),\n                                       num_joints_}); ++i) {\n            double compensation = compensators_[i]->updateCompensation(\n                sim_positions[i], real_positions[i]);\n\n            compensated_commands[i] = compensators_[i]->applyCompensation(\n                sim_commands[i]);\n        }\n\n        return compensated_commands;\n    }\n\nprivate:\n    std::vector<std::unique_ptr<AdaptiveCompensator>> compensators_;\n    size_t num_joints_;\n};\n"})}),"\n",(0,a.jsxs)(e.ol,{start:"3",children:["\n",(0,a.jsx)(e.li,{children:(0,a.jsx)(e.strong,{children:"Validation and monitoring:"})}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"The system includes comprehensive validation:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Real-time performance metrics"}),"\n",(0,a.jsx)(e.li,{children:"Success/failure classification"}),"\n",(0,a.jsx)(e.li,{children:"Parameter monitoring and logging"}),"\n",(0,a.jsx)(e.li,{children:"Automatic adjustment of compensation parameters"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"understanding-the-implementation",children:"Understanding the Implementation"}),"\n",(0,a.jsx)(e.p,{children:"The glass-box view reveals:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"The system uses multiple techniques (domain randomization, system identification, adaptive control) to handle the reality gap"}),"\n",(0,a.jsx)(e.li,{children:"Real-time learning allows the system to adapt to changing conditions"}),"\n",(0,a.jsx)(e.li,{children:"Comprehensive validation ensures the transfer remains effective"}),"\n",(0,a.jsx)(e.li,{children:"The modular design allows different components to be used independently or together"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"tiered-assessments",children:"Tiered Assessments"}),"\n",(0,a.jsx)(e.h3,{id:"tier-1-basic-understanding",children:"Tier 1: Basic Understanding"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsx)(e.li,{children:'What is the "reality gap" in robotics?'}),"\n",(0,a.jsx)(e.li,{children:"Name three sources of sim-to-real transfer challenges."}),"\n",(0,a.jsx)(e.li,{children:"What is domain randomization and why is it useful?"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"tier-2-application",children:"Tier 2: Application"}),"\n",(0,a.jsxs)(e.ol,{start:"4",children:["\n",(0,a.jsx)(e.li,{children:"Implement a basic reality gap compensation system for a simulated humanoid robot."}),"\n",(0,a.jsx)(e.li,{children:"Design a validation procedure to measure sim-to-real transfer performance."}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"tier-3-analysis-and-synthesis",children:"Tier 3: Analysis and Synthesis"}),"\n",(0,a.jsxs)(e.ol,{start:"6",children:["\n",(0,a.jsx)(e.li,{children:"Design a complete sim-to-real transfer system that includes system identification, adaptive compensation, and performance validation for humanoid robot locomotion."}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"mermaid-diagram",children:"Mermaid Diagram"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-mermaid",children:"graph TB\n    A[Simulation] --\x3e B[Sim Robot State]\n    C[Real Robot] --\x3e D[Real Robot State]\n\n    B --\x3e E[System Identification]\n    D --\x3e E\n    E --\x3e F[Model Parameters]\n\n    B --\x3e G[Reality Gap Compensation]\n    D --\x3e G\n    F --\x3e G\n\n    G --\x3e H[Compensated Commands]\n    H --\x3e C\n\n    B --\x3e I[Transfer Validation]\n    D --\x3e I\n    I --\x3e J[Success Metrics]\n\n    J --\x3e K[Adaptive Learning]\n    K --\x3e G\n\n    style A fill:#ff9999\n    style C fill:#ff9999\n    style G fill:#99ccff\n    style I fill:#99ff99\n"})}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Alt-text for diagram:"}),' "Sim-to-real transfer system showing simulation and real robot as input sources. Simulation connects to sim robot state, and real robot connects to real robot state. Both states connect to system identification, which outputs model parameters to reality gap compensation. Sim robot state and real robot state also connect directly to reality gap compensation. The compensation outputs compensated commands back to the real robot. Both sim and real robot states also connect to transfer validation, which outputs success metrics. Success metrics connect to adaptive learning, which feeds back to reality gap compensation. Simulated and real robots are highlighted in pink, the compensation system in light blue, and validation system in light green."']}),"\n",(0,a.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsx)(e.p,{children:"This chapter covered the critical techniques for achieving successful sim-to-real transfer in humanoid robotics. We explored the theoretical foundations of the reality gap, implemented practical compensation systems, and demonstrated how to validate transfer performance. The examples showed how to combine domain randomization, system identification, and adaptive control to bridge the gap between simulation and reality for humanoid robots."}),"\n",(0,a.jsx)(e.h2,{id:"references",children:"References"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:["Sadeghi, F., & Levine, S. (2017). CAD2RL: Real single-image flight without a single real image. ",(0,a.jsx)(e.em,{children:"Proceedings of the 1st Annual Conference on Robot Learning"}),", 209-219."]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:["Peng, X. B., Andry, P., Zhang, E., Abbeel, P., & Dragan, A. (2018). Sim-to-real transfer of robotic control with dynamics randomization. ",(0,a.jsx)(e.em,{children:"2018 IEEE International Conference on Robotics and Automation (ICRA)"}),", 1-8."]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:["James, S., Davison, A. J., & Johns, E. (2019). Translating images across domains for real-world robot navigation. ",(0,a.jsx)(e.em,{children:"2019 International Conference on Robotics and Automation (ICRA)"}),", 5399-5405."]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:["Tan, J., Zhang, T., Coumans, E., Iscen, A., Bai, Y., Hafner, D., ... & Vanhoucke, V. (2018). Sim-to-real: Learning agile robotic locomotion skills in simulation. ",(0,a.jsx)(e.em,{children:"arXiv preprint arXiv:1804.10332"}),"."]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:["Chebotar, Y., Handa, A., Li, V., Morales, A., Hutter, M., & Birchfield, S. (2019). Closing the sim-to-real loop: Adapting simulation randomizations with real world experience. ",(0,a.jsx)(e.em,{children:"2019 International Conference on Robotics and Automation (ICRA)"}),", 8973-8979."]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:["Rajeswaran, A., Kumar, V., Gupta, A., & Todorov, E. (2017). Learning complex dexterous manipulation with deep reinforcement learning and demonstrations. ",(0,a.jsx)(e.em,{children:"arXiv preprint arXiv:1709.10087"}),"."]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:["Pinto, L., Gandhi, D., Han, Y., Seita, D., & Levine, S. (2017). The office marathon: Nearly autonomous mapping of an indoor office environment with a consumer UAV. ",(0,a.jsx)(e.em,{children:"Robotics: Science and Systems"}),"."]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:["Tobin, J., Fong, R., Ray, A., Schneider, J., Zaremba, W., & Abbeel, P. (2017). Domain randomization for transferring deep neural networks from simulation to the real world. ",(0,a.jsx)(e.em,{children:"2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)"}),", 23-30."]}),"\n"]}),"\n"]})]})}function m(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>o,x:()=>r});var t=i(6540);const a={},s=t.createContext(a);function o(n){const e=t.useContext(s);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:o(n.components),t.createElement(s.Provider,{value:e},n.children)}}}]);