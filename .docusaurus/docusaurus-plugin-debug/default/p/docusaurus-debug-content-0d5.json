{"allContent":{"docusaurus-plugin-content-docs":{"default":{"loadedVersions":[{"versionName":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","path":"/","tagsPath":"/tags","editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs","isLast":true,"routePriority":-1,"sidebarFilePath":"/home/farhan-rajput/Hackathoon_Q4/AI-And-Robotic-Hackathoon/sidebars.js","contentPath":"/home/farhan-rajput/Hackathoon_Q4/AI-And-Robotic-Hackathoon/docs","docs":[{"id":"Chatbot","title":"AI Assistant","description":"Welcome to the interactive AI Assistant for the Physical AI & Humanoid Robotics textbook! This AI-powered assistant is designed to help you understand complex concepts, answer questions, and provide explanations based on the textbook content.","source":"@site/docs/Chatbot.md","sourceDirName":".","slug":"/Chatbot","permalink":"/Chatbot","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/Chatbot.md","tags":[],"version":"current","frontMatter":{"title":"AI Assistant"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 4: Capstone: Autonomous Humanoid (Complete End-to-End System)","permalink":"/vla/capstone-autonomous-humanoid"},"next":{"title":"Constitution of the Physical AI & Humanoid Robotics Textbook","permalink":"/Constitution"}},{"id":"Constitution","title":"Constitution of the Physical AI & Humanoid Robotics Textbook","description":"Preamble","source":"@site/docs/Constitution.md","sourceDirName":".","slug":"/Constitution","permalink":"/Constitution","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/Constitution.md","tags":[],"version":"current","frontMatter":{"title":"Constitution of the Physical AI & Humanoid Robotics Textbook"},"sidebar":"tutorialSidebar","previous":{"title":"AI Assistant","permalink":"/Chatbot"},"next":{"title":"Constitution of the Integrated RAG Chatbot","permalink":"/RAG-Chatbot-Constitution"}},{"id":"contributors","title":"Contributors","description":"The \"Physical AI & Humanoid Robotics\" textbook is the result of collaborative effort from experts across multiple disciplines. We acknowledge and thank all individuals who contributed to this educational resource.","source":"@site/docs/contributors.md","sourceDirName":".","slug":"/contributors","permalink":"/contributors","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/contributors.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Constitution of the Integrated RAG Chatbot","permalink":"/RAG-Chatbot-Constitution"},"next":{"title":"Deployment Guide for GitHub Pages","permalink":"/deployment"}},{"id":"deployment","title":"Deployment Guide for GitHub Pages","description":"This guide provides step-by-step instructions for deploying the Docusaurus site to GitHub Pages.","source":"@site/docs/deployment.md","sourceDirName":".","slug":"/deployment","permalink":"/deployment","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/deployment.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Contributors","permalink":"/contributors"},"next":{"title":"Getting Started with Physical AI & Humanoid Robotics Textbook","permalink":"/getting-started"}},{"id":"digital-twin/creating-complete-digital-twins","title":"Creating Complete Digital Twins","description":"Learning Objectives","source":"@site/docs/02-digital-twin/04-creating-complete-digital-twins.md","sourceDirName":"02-digital-twin","slug":"/digital-twin/creating-complete-digital-twins","permalink":"/digital-twin/creating-complete-digital-twins","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/02-digital-twin/04-creating-complete-digital-twins.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"Creating Complete Digital Twins"},"sidebar":"moduleSidebar","previous":{"title":"Unity for High-Fidelity HRI","permalink":"/digital-twin/unity-for-high-fidelity-hri"},"next":{"title":"Isaac Sim & Synthetic Data Generation","permalink":"/nvidia-isaac/isaac-sim-synthetic-data"}},{"id":"digital-twin/gazebo-physics-and-world-building","title":"Gazebo Physics & World Building","description":"Learning Objectives","source":"@site/docs/02-digital-twin/01-gazebo-physics-and-world-building.md","sourceDirName":"02-digital-twin","slug":"/digital-twin/gazebo-physics-and-world-building","permalink":"/digital-twin/gazebo-physics-and-world-building","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/02-digital-twin/01-gazebo-physics-and-world-building.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"Gazebo Physics & World Building"},"sidebar":"moduleSidebar","previous":{"title":"Python rclpy Bridge to Controllers","permalink":"/ros2/python-rclpy-bridge"},"next":{"title":"Sensor Simulation (LiDAR, Depth, IMU)","permalink":"/digital-twin/simulating-sensors-lidar-imu-depth"}},{"id":"digital-twin/simulating-sensors-lidar-imu-depth","title":"Sensor Simulation (LiDAR, Depth, IMU)","description":"Learning Objectives","source":"@site/docs/02-digital-twin/02-simulating-sensors-lidar-imu-depth.md","sourceDirName":"02-digital-twin","slug":"/digital-twin/simulating-sensors-lidar-imu-depth","permalink":"/digital-twin/simulating-sensors-lidar-imu-depth","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/02-digital-twin/02-simulating-sensors-lidar-imu-depth.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Sensor Simulation (LiDAR, Depth, IMU)"},"sidebar":"moduleSidebar","previous":{"title":"Gazebo Physics & World Building","permalink":"/digital-twin/gazebo-physics-and-world-building"},"next":{"title":"Unity for High-Fidelity HRI","permalink":"/digital-twin/unity-for-high-fidelity-hri"}},{"id":"digital-twin/unity-for-high-fidelity-hri","title":"Unity for High-Fidelity HRI","description":"Learning Objectives","source":"@site/docs/02-digital-twin/03-unity-for-high-fidelity-hri.md","sourceDirName":"02-digital-twin","slug":"/digital-twin/unity-for-high-fidelity-hri","permalink":"/digital-twin/unity-for-high-fidelity-hri","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/02-digital-twin/03-unity-for-high-fidelity-hri.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"Unity for High-Fidelity HRI"},"sidebar":"moduleSidebar","previous":{"title":"Sensor Simulation (LiDAR, Depth, IMU)","permalink":"/digital-twin/simulating-sensors-lidar-imu-depth"},"next":{"title":"Creating Complete Digital Twins","permalink":"/digital-twin/creating-complete-digital-twins"}},{"id":"getting-started","title":"Getting Started with Physical AI & Humanoid Robotics Textbook","description":"Welcome to the \"Physical AI & Humanoid Robotics\" textbook website! This guide will help you set up and run the educational content on your local machine.","source":"@site/docs/getting-started.md","sourceDirName":".","slug":"/getting-started","permalink":"/getting-started","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/getting-started.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Deployment Guide for GitHub Pages","permalink":"/deployment"},"next":{"title":"Introduction","permalink":"/intro"}},{"id":"intro","title":"Introduction","description":"Welcome to \"Physical AI & Humanoid Robotics,\" a comprehensive textbook designed to guide you through the fascinating world of intelligent humanoid systems. This textbook is structured into four progressive modules that build upon each other to provide a complete understanding of how to design, develop, and deploy intelligent robots.","source":"@site/docs/intro.md","sourceDirName":".","slug":"/intro","permalink":"/intro","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/intro.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","next":{"title":"Module 1: The Robotic Nervous System (ROS 2)","permalink":"/category/module-1-the-robotic-nervous-system-ros-2"}},{"id":"local-verification-checklist","title":"Local Verification Checklist for Physical AI & Humanoid Robotics Textbook Site","description":"This checklist ensures that the Docusaurus textbook site is fully functional before public release. Complete each item to verify the site works correctly on http3000.","source":"@site/docs/local-verification-checklist.md","sourceDirName":".","slug":"/local-verification-checklist","permalink":"/local-verification-checklist","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/local-verification-checklist.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Introduction","permalink":"/intro"},"next":{"title":"Preface","permalink":"/preface"}},{"id":"nvidia-isaac/isaac-ros-vslam-perception","title":"Isaac ROS + Hardware-Accelerated VSLAM","description":"Learning Objectives","source":"@site/docs/03-nvidia-isaac/02-isaac-ros-vslam-perception.md","sourceDirName":"03-nvidia-isaac","slug":"/nvidia-isaac/isaac-ros-vslam-perception","permalink":"/nvidia-isaac/isaac-ros-vslam-perception","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/03-nvidia-isaac/02-isaac-ros-vslam-perception.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Isaac ROS + Hardware-Accelerated VSLAM"},"sidebar":"moduleSidebar","previous":{"title":"Isaac Sim & Synthetic Data Generation","permalink":"/nvidia-isaac/isaac-sim-synthetic-data"},"next":{"title":"Nav2 for Bipedal Humanoids","permalink":"/nvidia-isaac/nav2-bipedal-locomotion"}},{"id":"nvidia-isaac/isaac-sim-synthetic-data","title":"Isaac Sim & Synthetic Data Generation","description":"Learning Objectives","source":"@site/docs/03-nvidia-isaac/01-isaac-sim-synthetic-data.md","sourceDirName":"03-nvidia-isaac","slug":"/nvidia-isaac/isaac-sim-synthetic-data","permalink":"/nvidia-isaac/isaac-sim-synthetic-data","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/03-nvidia-isaac/01-isaac-sim-synthetic-data.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"Isaac Sim & Synthetic Data Generation"},"sidebar":"moduleSidebar","previous":{"title":"Creating Complete Digital Twins","permalink":"/digital-twin/creating-complete-digital-twins"},"next":{"title":"Isaac ROS + Hardware-Accelerated VSLAM","permalink":"/nvidia-isaac/isaac-ros-vslam-perception"}},{"id":"nvidia-isaac/nav2-bipedal-locomotion","title":"Nav2 for Bipedal Humanoids","description":"Learning Objectives","source":"@site/docs/03-nvidia-isaac/03-nav2-bipedal-locomotion.md","sourceDirName":"03-nvidia-isaac","slug":"/nvidia-isaac/nav2-bipedal-locomotion","permalink":"/nvidia-isaac/nav2-bipedal-locomotion","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/03-nvidia-isaac/03-nav2-bipedal-locomotion.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"Nav2 for Bipedal Humanoids"},"sidebar":"moduleSidebar","previous":{"title":"Isaac ROS + Hardware-Accelerated VSLAM","permalink":"/nvidia-isaac/isaac-ros-vslam-perception"},"next":{"title":"Sim-to-Real Transfer Techniques","permalink":"/nvidia-isaac/sim-to-real-transfer"}},{"id":"nvidia-isaac/sim-to-real-transfer","title":"Sim-to-Real Transfer Techniques","description":"Learning Objectives","source":"@site/docs/03-nvidia-isaac/04-sim-to-real-transfer.md","sourceDirName":"03-nvidia-isaac","slug":"/nvidia-isaac/sim-to-real-transfer","permalink":"/nvidia-isaac/sim-to-real-transfer","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/03-nvidia-isaac/04-sim-to-real-transfer.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"Sim-to-Real Transfer Techniques"},"sidebar":"moduleSidebar","previous":{"title":"Nav2 for Bipedal Humanoids","permalink":"/nvidia-isaac/nav2-bipedal-locomotion"},"next":{"title":"Chapter 1: Voice-to-Action using OpenAI Whisper (Local Implementation)","permalink":"/vla/voice-to-action-with-whisper"}},{"id":"preface","title":"Preface","description":"The field of robotics has experienced unprecedented growth in recent years, with humanoid robots representing one of the most ambitious frontiers in artificial intelligence and engineering. \"Physical AI & Humanoid Robotics\" is designed to bridge the gap between theoretical knowledge and practical implementation, providing students and professionals with the comprehensive understanding needed to develop intelligent humanoid systems.","source":"@site/docs/preface.md","sourceDirName":".","slug":"/preface","permalink":"/preface","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/preface.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Local Verification Checklist for Physical AI & Humanoid Robotics Textbook Site","permalink":"/local-verification-checklist"},"next":{"title":"Troubleshooting Guide for Physical AI & Humanoid Robotics Textbook Site","permalink":"/troubleshooting"}},{"id":"RAG-Chatbot-Constitution","title":"Constitution of the Integrated RAG Chatbot","description":"Preamble","source":"@site/docs/RAG-Chatbot-Constitution.md","sourceDirName":".","slug":"/RAG-Chatbot-Constitution","permalink":"/RAG-Chatbot-Constitution","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/RAG-Chatbot-Constitution.md","tags":[],"version":"current","frontMatter":{"title":"Constitution of the Integrated RAG Chatbot"},"sidebar":"tutorialSidebar","previous":{"title":"Constitution of the Physical AI & Humanoid Robotics Textbook","permalink":"/Constitution"},"next":{"title":"Contributors","permalink":"/contributors"}},{"id":"ros2/nodes-topics-services-actions","title":"Nodes, Topics, Services, and Actions","description":"Learning Objectives","source":"@site/docs/01-ros2/02-nodes-topics-services-actions.md","sourceDirName":"01-ros2","slug":"/ros2/nodes-topics-services-actions","permalink":"/ros2/nodes-topics-services-actions","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/01-ros2/02-nodes-topics-services-actions.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Nodes, Topics, Services, and Actions"},"sidebar":"moduleSidebar","previous":{"title":"ROS 2 and Embodied Control","permalink":"/ros2/ros2-and-embodied-control"},"next":{"title":"URDF + Xacro for Humanoids","permalink":"/ros2/urdf-xacro-for-humanoids"}},{"id":"ros2/python-rclpy-bridge","title":"Python rclpy Bridge to Controllers","description":"Learning Objectives","source":"@site/docs/01-ros2/04-python-rclpy-bridge.md","sourceDirName":"01-ros2","slug":"/ros2/python-rclpy-bridge","permalink":"/ros2/python-rclpy-bridge","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/01-ros2/04-python-rclpy-bridge.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"Python rclpy Bridge to Controllers"},"sidebar":"moduleSidebar","previous":{"title":"URDF + Xacro for Humanoids","permalink":"/ros2/urdf-xacro-for-humanoids"},"next":{"title":"Gazebo Physics & World Building","permalink":"/digital-twin/gazebo-physics-and-world-building"}},{"id":"ros2/ros2-and-embodied-control","title":"ROS 2 and Embodied Control","description":"Learning Objectives","source":"@site/docs/01-ros2/01-ros2-and-embodied-control.md","sourceDirName":"01-ros2","slug":"/ros2/ros2-and-embodied-control","permalink":"/ros2/ros2-and-embodied-control","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/01-ros2/01-ros2-and-embodied-control.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"ROS 2 and Embodied Control"},"sidebar":"moduleSidebar","next":{"title":"Nodes, Topics, Services, and Actions","permalink":"/ros2/nodes-topics-services-actions"}},{"id":"ros2/urdf-xacro-for-humanoids","title":"URDF + Xacro for Humanoids","description":"Learning Objectives","source":"@site/docs/01-ros2/03-urdf-xacro-for-humanoids.md","sourceDirName":"01-ros2","slug":"/ros2/urdf-xacro-for-humanoids","permalink":"/ros2/urdf-xacro-for-humanoids","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/01-ros2/03-urdf-xacro-for-humanoids.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"URDF + Xacro for Humanoids"},"sidebar":"moduleSidebar","previous":{"title":"Nodes, Topics, Services, and Actions","permalink":"/ros2/nodes-topics-services-actions"},"next":{"title":"Python rclpy Bridge to Controllers","permalink":"/ros2/python-rclpy-bridge"}},{"id":"troubleshooting","title":"Troubleshooting Guide for Physical AI & Humanoid Robotics Textbook Site","description":"This guide addresses common issues that may occur when setting up or running the Docusaurus textbook site.","source":"@site/docs/troubleshooting.md","sourceDirName":".","slug":"/troubleshooting","permalink":"/troubleshooting","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/troubleshooting.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Preface","permalink":"/preface"}},{"id":"vla/capstone-autonomous-humanoid","title":"Chapter 4: Capstone: Autonomous Humanoid (Complete End-to-End System)","description":"Learning Objectives","source":"@site/docs/04-vla/04-capstone-autonomous-humanoid.md","sourceDirName":"04-vla","slug":"/vla/capstone-autonomous-humanoid","permalink":"/vla/capstone-autonomous-humanoid","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/04-vla/04-capstone-autonomous-humanoid.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{},"sidebar":"moduleSidebar","previous":{"title":"Multi-Modal Integration","permalink":"/vla/multi-modal-integration"}},{"id":"vla/llm-task-and-motion-planning","title":"Chapter 2: LLM Task & Motion Planning (Natural Language → ROS Actions)","description":"Learning Objectives","source":"@site/docs/04-vla/02-llm-task-and-motion-planning.md","sourceDirName":"04-vla","slug":"/vla/llm-task-and-motion-planning","permalink":"/vla/llm-task-and-motion-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/04-vla/02-llm-task-and-motion-planning.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{},"sidebar":"moduleSidebar","previous":{"title":"Chapter 1: Voice-to-Action using OpenAI Whisper (Local Implementation)","permalink":"/vla/voice-to-action-with-whisper"},"next":{"title":"Multi-Modal Integration","permalink":"/vla/multi-modal-integration"}},{"id":"vla/multi-modal-integration","title":"Multi-Modal Integration","description":"Learning Objectives","source":"@site/docs/04-vla/03-multi-modal-integration.md","sourceDirName":"04-vla","slug":"/vla/multi-modal-integration","permalink":"/vla/multi-modal-integration","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/04-vla/03-multi-modal-integration.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"Multi-Modal Integration"},"sidebar":"moduleSidebar","previous":{"title":"Chapter 2: LLM Task & Motion Planning (Natural Language → ROS Actions)","permalink":"/vla/llm-task-and-motion-planning"},"next":{"title":"Chapter 4: Capstone: Autonomous Humanoid (Complete End-to-End System)","permalink":"/vla/capstone-autonomous-humanoid"}},{"id":"vla/voice-to-action-with-whisper","title":"Chapter 1: Voice-to-Action using OpenAI Whisper (Local Implementation)","description":"Learning Objectives","source":"@site/docs/04-vla/01-voice-to-action-with-whisper.md","sourceDirName":"04-vla","slug":"/vla/voice-to-action-with-whisper","permalink":"/vla/voice-to-action-with-whisper","draft":false,"unlisted":false,"editUrl":"https://github.com/mfsrajput/AI-And-Robotic-Hackathoon/edit/main/docs/04-vla/01-voice-to-action-with-whisper.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{},"sidebar":"moduleSidebar","previous":{"title":"Sim-to-Real Transfer Techniques","permalink":"/nvidia-isaac/sim-to-real-transfer"},"next":{"title":"Chapter 2: LLM Task & Motion Planning (Natural Language → ROS Actions)","permalink":"/vla/llm-task-and-motion-planning"}}],"drafts":[],"sidebars":{"tutorialSidebar":[{"type":"doc","id":"intro"},{"type":"category","label":"Module 1: The Robotic Nervous System (ROS 2)","collapsible":true,"collapsed":true,"items":[{"type":"doc","id":"ros2/ros2-and-embodied-control"},{"type":"doc","id":"ros2/nodes-topics-services-actions"},{"type":"doc","id":"ros2/urdf-xacro-for-humanoids"},{"type":"doc","id":"ros2/python-rclpy-bridge"}],"link":{"type":"generated-index","description":"Introduction to ROS 2 concepts for embodied control systems in humanoid robotics","slug":"/category/module-1-the-robotic-nervous-system-ros-2","permalink":"/category/module-1-the-robotic-nervous-system-ros-2"}},{"type":"category","label":"Module 2: The Digital Twin (Gazebo & Unity)","collapsible":true,"collapsed":true,"items":[{"type":"doc","id":"digital-twin/gazebo-physics-and-world-building"},{"type":"doc","id":"digital-twin/simulating-sensors-lidar-imu-depth"},{"type":"doc","id":"digital-twin/unity-for-high-fidelity-hri"},{"type":"doc","id":"digital-twin/creating-complete-digital-twins"}],"link":{"type":"generated-index","description":"Creating digital twins for humanoid robots using Gazebo physics simulation and Unity for high-fidelity human-robot interaction","slug":"/category/module-2-the-digital-twin-gazebo--unity","permalink":"/category/module-2-the-digital-twin-gazebo--unity"}},{"type":"category","label":"Module 3: The AI-Robot Brain (NVIDIA Isaac)","collapsible":true,"collapsed":true,"items":[{"type":"doc","id":"nvidia-isaac/isaac-sim-synthetic-data"},{"type":"doc","id":"nvidia-isaac/isaac-ros-vslam-perception"},{"type":"doc","id":"nvidia-isaac/nav2-bipedal-locomotion"},{"type":"doc","id":"nvidia-isaac/sim-to-real-transfer"}],"link":{"type":"generated-index","description":"Advanced AI and perception systems for humanoid robots using NVIDIA Isaac Sim and ROS for synthetic data generation, VSLAM, and sim-to-real transfer","slug":"/category/module-3-the-ai-robot-brain-nvidia-isaac","permalink":"/category/module-3-the-ai-robot-brain-nvidia-isaac"}},{"type":"category","label":"Module 4: Vision-Language-Action (VLA) + Capstone","collapsible":true,"collapsed":true,"items":[{"type":"doc","id":"vla/voice-to-action-with-whisper"},{"type":"doc","id":"vla/llm-task-and-motion-planning"},{"type":"doc","id":"vla/multi-modal-integration"},{"type":"doc","id":"vla/capstone-autonomous-humanoid"}],"link":{"type":"generated-index","title":"Vision-Language-Action (VLA) + Capstone","slug":"/category/module-4-vision-language-action-vla--capstone","permalink":"/category/module-4-vision-language-action-vla--capstone"}},{"type":"doc","id":"Chatbot"},{"type":"doc","id":"Constitution"},{"type":"doc","id":"RAG-Chatbot-Constitution"},{"type":"doc","id":"contributors"},{"type":"doc","id":"deployment"},{"type":"doc","id":"getting-started"},{"type":"doc","id":"intro"},{"type":"doc","id":"local-verification-checklist"},{"type":"doc","id":"preface"},{"type":"doc","id":"troubleshooting"}],"moduleSidebar":[{"type":"category","label":"Module 1: ROS 2 Fundamentals","items":[{"type":"doc","id":"ros2/ros2-and-embodied-control"},{"type":"doc","id":"ros2/nodes-topics-services-actions"},{"type":"doc","id":"ros2/urdf-xacro-for-humanoids"},{"type":"doc","id":"ros2/python-rclpy-bridge"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2: Digital Twin","items":[{"type":"doc","id":"digital-twin/gazebo-physics-and-world-building"},{"type":"doc","id":"digital-twin/simulating-sensors-lidar-imu-depth"},{"type":"doc","id":"digital-twin/unity-for-high-fidelity-hri"},{"type":"doc","id":"digital-twin/creating-complete-digital-twins"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3: NVIDIA Isaac Sim","items":[{"type":"doc","id":"nvidia-isaac/isaac-sim-synthetic-data"},{"type":"doc","id":"nvidia-isaac/isaac-ros-vslam-perception"},{"type":"doc","id":"nvidia-isaac/nav2-bipedal-locomotion"},{"type":"doc","id":"nvidia-isaac/sim-to-real-transfer"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4: Vision-Language-Action (VLA) System","items":[{"type":"doc","id":"vla/voice-to-action-with-whisper"},{"type":"doc","id":"vla/llm-task-and-motion-planning"},{"type":"doc","id":"vla/multi-modal-integration"},{"type":"doc","id":"vla/capstone-autonomous-humanoid"}],"collapsed":true,"collapsible":true}]}}]}},"docusaurus-plugin-content-pages":{"default":[{"type":"mdx","permalink":"/","source":"@site/src/pages/index.md","title":"Physical AI & Humanoid Robotics","description":"Building Intelligent Humanoid Robots for the Future","frontMatter":{"title":"Physical AI & Humanoid Robotics"},"unlisted":false}]},"docusaurus-plugin-debug":{},"docusaurus-plugin-svgr":{},"docusaurus-theme-classic":{},"docusaurus-bootstrap-plugin":{},"docusaurus-mdx-fallback-plugin":{}}}